{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>embarked_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class  embark_town  alone  embarked_encode  \n",
       "0        S  Third  Southampton      0                3  \n",
       "1        C  First    Cherbourg      0                0  \n",
       "2        S  Third  Southampton      1                3  \n",
       "3        S  First  Southampton      0                3  \n",
       "4        S  Third  Southampton      1                3  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "\n",
    "from graphviz import Graph\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from acquire import get_titanic_data\n",
    "from prepare import prep_titanic_data\n",
    "\n",
    "df = prep_titanic_data(get_titanic_data())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values in the 'age' column\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.9000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass   age      fare  sibsp  parch\n",
       "60        3  22.0    7.2292      0      0\n",
       "348       3   3.0   15.9000      1      1\n",
       "606       3  30.0    7.8958      0      0\n",
       "195       1  58.0  146.5208      0      0\n",
       "56        2  21.0   10.5000      0      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['pclass','age','fare','sibsp','parch']]\n",
    "y = df[['survived']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make the thing\n",
    "logit = LogisticRegression(C=1, class_weight={1:2}, random_state = 123, solver='saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight={1: 2}, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=123, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Fit\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.03183343 -0.00819677  0.01882492 -0.02030296  0.01317287]]\n",
      "Intercept: \n",
      " [0.00230414]\n"
     ]
    }
   ],
   "source": [
    "# 3. Do stuff\n",
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fit the logistic regression classifier to your training sample and transform, i.e. make predictions on the training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate whether a passenger would survive\n",
    "y_pred = logit.predict(X_train)\n",
    "\n",
    "# Estimate the probability of a passenger surviving\n",
    "y_pred_proba = logit.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression classifier on        training set (Model Score):        0.6472945891783567\n"
     ]
    }
   ],
   "source": [
    "# Model score\n",
    "print(f'Accuracy of the Logistic Regression classifier on\\\n",
    "        training set (Model Score):\\\n",
    "        {logit.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[181 112]\n",
      " [ 64 142]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_train, y_pred),\n",
    "                 columns=['Pred -', 'Pred +'], index=['Actual -', 'Actual +'])\n",
    "# cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.62      0.67       293\n",
      "           1       0.56      0.69      0.62       206\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       499\n",
      "   macro avg       0.65      0.65      0.65       499\n",
      "weighted avg       0.66      0.65      0.65       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: \t 0.6893203883495146\n",
      "Precision: \t 0.5590551181102362\n",
      "F1: \t\t 0.6241877532298754\n",
      "Support: \t 206\n"
     ]
    }
   ],
   "source": [
    "tp = cm.loc['Actual +', 'Pred +']\n",
    "fn = cm.loc['Actual +', 'Pred -']\n",
    "fp = cm.loc['Actual -', 'Pred +']\n",
    "tn = cm.loc['Actual -', 'Pred -']\n",
    "\n",
    "recall = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "f1 = (recall + precision) / 2\n",
    "support = tp + fn\n",
    "\n",
    "print(f'Recall: \\t {recall}')\n",
    "print(f'Precision: \\t {precision}')\n",
    "print(f'F1: \\t\\t {f1}')\n",
    "print(f'Support: \\t {support}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model score\n",
    "# print(f'Accuracy of the Logistic Regression classifier on\\\n",
    "#         test set (Model Score):\\\n",
    "#         {logit.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Look in the scikit-learn documentation to research the solver parameter. What is your best option(s) for the particular problem you are trying to solve and the data to be used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use liblinear instead of saga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Run through steps 2-4 using another solver (from question 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.87476501 -0.02505375  0.00588046 -0.28755904  0.37926043]]\n",
      "Intercept: \n",
      " [2.76511655]\n",
      "Accuracy of the Logistic Regression classifier on        training set (Model Score):        0.6993987975951904\n",
      "[[194  99]\n",
      " [ 51 155]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred -</th>\n",
       "      <th>Pred +</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual -</th>\n",
       "      <td>194</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual +</th>\n",
       "      <td>51</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred -  Pred +\n",
       "Actual -     194      99\n",
       "Actual +      51     155"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Make the thing\n",
    "logit = LogisticRegression(C=1, class_weight={1:2}, random_state = 123, solver='liblinear')\n",
    "\n",
    "# 2. Fit\n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "# 3. Do stuff\n",
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)\n",
    "\n",
    "# Estimate whether a passenger would survive\n",
    "y_pred = logit.predict(X_train)\n",
    "\n",
    "# Estimate the probability of a passenger surviving\n",
    "y_pred_proba = logit.predict_proba(X_train)\n",
    "\n",
    "# Model score\n",
    "print(f'Accuracy of the Logistic Regression classifier on\\\n",
    "        training set (Model Score):\\\n",
    "        {logit.score(X_train, y_train)}')\n",
    "\n",
    "# Confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_train, y_pred),\n",
    "                 columns=['Pred -', 'Pred +'], index=['Actual -', 'Actual +'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.66      0.72       293\n",
      "           1       0.61      0.75      0.67       206\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       499\n",
      "   macro avg       0.70      0.71      0.70       499\n",
      "weighted avg       0.72      0.70      0.70       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: \t 0.7524271844660194\n",
      "Precision: \t 0.610236220472441\n",
      "F1: \t\t 0.6813317024692302\n",
      "Support: \t 206\n"
     ]
    }
   ],
   "source": [
    "tp = cm.loc['Actual +', 'Pred +']\n",
    "fn = cm.loc['Actual +', 'Pred -']\n",
    "fp = cm.loc['Actual -', 'Pred +']\n",
    "tn = cm.loc['Actual -', 'Pred -']\n",
    "\n",
    "recall = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "f1 = (recall + precision) / 2\n",
    "support = tp + fn\n",
    "\n",
    "print(f'Recall: \\t {recall}')\n",
    "print(f'Precision: \\t {precision}')\n",
    "print(f'F1: \\t\\t {f1}')\n",
    "print(f'Support: \\t {support}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Which performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liblinear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Save the best model in logit_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_fit = logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model score\n",
    "# print(f'Accuracy of the Logistic Regression classifier on\\\n",
    "#         test set (Model Score):\\\n",
    "#         {logit.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree - Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
       "1           5.1          3.5           1.4          0.2  setosa\n",
       "2           4.9          3.0           1.4          0.2  setosa\n",
       "3           4.7          3.2           1.3          0.2  setosa\n",
       "4           4.6          3.1           1.5          0.2  setosa\n",
       "5           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "df = data('iris')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [col.lower().replace('.', '_') for col in df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "115           5.8          2.8           5.1          2.4\n",
       "137           6.3          3.4           5.6          2.4\n",
       "54            5.5          2.3           4.0          1.3\n",
       "20            5.1          3.8           1.5          0.3\n",
       "39            4.4          3.0           1.3          0.2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['species'],axis=1)\n",
    "y = df[['species']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the decision tree classifier to your training sample and transform, i.e. make predictions on the training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make the thing\n",
    "clf = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.5  , 0.5  ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [0.   , 0.5  , 0.5  ],\n",
       "       [0.   , 0.   , 1.   ]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Do stuff\n",
    "\n",
    "# Estimate species\n",
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:5]\n",
    "\n",
    "# Estimate the probability of a species\n",
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.98\n",
      "[[32  0  0]\n",
      " [ 0 40  0]\n",
      " [ 0  2 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.95      1.00      0.98        40\n",
      "           2       1.00      0.94      0.97        33\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       105\n",
      "   macro avg       0.98      0.98      0.98       105\n",
      "weighted avg       0.98      0.98      0.98       105\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9809523809523809"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model score\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "\n",
    "# Confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "\n",
    "labels = sorted(y_train.species.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_train, y_pred))\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: \t 0.7524271844660194\n",
      "Precision: \t 0.610236220472441\n",
      "F1: \t\t 0.6813317024692302\n",
      "Support: \t 206\n"
     ]
    }
   ],
   "source": [
    "print(f'Recall: \\t {recall}')\n",
    "print(f'Precision: \\t {precision}')\n",
    "print(f'F1: \\t\\t {f1}')\n",
    "print(f'Support: \\t {support}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run through steps 2-4 using entropy as your measure of impurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.98\n",
      "[[32  0  0]\n",
      " [ 0 40  0]\n",
      " [ 0  2 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        32\n",
      "  versicolor       0.95      1.00      0.98        40\n",
      "   virginica       1.00      0.94      0.97        33\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       105\n",
      "   macro avg       0.98      0.98      0.98       105\n",
      "weighted avg       0.98      0.98      0.98       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Make the thing\n",
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=123)\n",
    "\n",
    "# 2. Fit\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 3. Do stuff\n",
    "\n",
    "# Estimate species\n",
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:5]\n",
    "\n",
    "# Estimate the probability of a species\n",
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "y_pred_proba\n",
    "\n",
    "# Model score\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "\n",
    "# Confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "\n",
    "labels = sorted(y_train.species.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_train, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Save the best model in tree_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_fit = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on test set: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Model score on TEST\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iris_decision_tree.pdf'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('iris_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree - Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acquire import get_titanic_data\n",
    "from prepare import prep_titanic_data\n",
    "\n",
    "df = prep_titanic_data(get_titanic_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>embarked_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class  embark_town  alone  embarked_encode  \n",
       "0        S  Third  Southampton      0                3  \n",
       "1        C  First    Cherbourg      0                0  \n",
       "2        S  Third  Southampton      1                3  \n",
       "3        S  First  Southampton      0                3  \n",
       "4        S  Third  Southampton      1                3  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex'] = df['sex'].map( {'female': 0, 'male': 1} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. make the thing\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 2. fit the thing\n",
    "scaler.fit(train[['age', 'fare']])\n",
    "\n",
    "# 3. use the thing\n",
    "train[['age', 'fare']] = scaler.transform(train[['age', 'fare']])\n",
    "test[['age', 'fare']] = scaler.transform(test[['age', 'fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>embarked_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>673</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.415602</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.225333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048655</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.061045</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>432</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.565099</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050749</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456374</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050749</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass  sex       age  sibsp  parch      fare  \\\n",
       "673           673         1       2    1  0.415602      0      0  0.025374   \n",
       "163           163         0       3    1  0.225333      0      0  0.016908   \n",
       "850           850         0       3    1  0.048655      4      2  0.061045   \n",
       "432           432         1       2    0  0.565099      1      0  0.050749   \n",
       "99             99         0       2    1  0.456374      1      0  0.050749   \n",
       "\n",
       "    embarked   class  embark_town  alone  embarked_encode  \n",
       "673        S  Second  Southampton      1                3  \n",
       "163        S   Third  Southampton      1                3  \n",
       "850        S   Third  Southampton      0                3  \n",
       "432        S  Second  Southampton      0                3  \n",
       "99         S  Second  Southampton      0                3  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>embarked_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.9000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass  sex   age  sibsp  parch      fare  alone  embarked_encode\n",
       "60        3    1  22.0      0      0    7.2292      1                0\n",
       "348       3    1   3.0      1      1   15.9000      0                3\n",
       "606       3    1  30.0      0      0    7.8958      1                3\n",
       "195       1    0  58.0      0      0  146.5208      1                0\n",
       "56        2    0  21.0      0      0   10.5000      1                3"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['passenger_id', 'embarked', 'class', 'embark_town', 'survived'],axis=1)\n",
    "y = df[['survived']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90134529, 0.09865471],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [1.        , 0.        ],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [1.        , 0.        ],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.        , 1.        ],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [1.        , 0.        ],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.        , 1.        ],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [1.        , 0.        ],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.        , 1.        ],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [1.        , 0.        ],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.5       , 0.5       ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [1.        , 0.        ],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [1.        , 0.        ],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [1.        , 0.        ],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.        , 1.        ],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.90134529, 0.09865471],\n",
       "       [0.60294118, 0.39705882]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.8176352705410822\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy of Decision Tree classifier on training set: {clf.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[252,  41],\n",
       "       [ 50, 156]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    293\n",
       "1    206\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>252</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  252   41\n",
       "1   50  156"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "labels = sorted(y_train.survived.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on test set: 0.80\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       293\n",
      "           1       0.79      0.76      0.77       206\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       499\n",
      "   macro avg       0.81      0.81      0.81       499\n",
      "weighted avg       0.82      0.82      0.82       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN - Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      "passenger_id       891 non-null int64\n",
      "survived           891 non-null int64\n",
      "pclass             891 non-null int64\n",
      "sex                891 non-null object\n",
      "age                714 non-null float64\n",
      "sibsp              891 non-null int64\n",
      "parch              891 non-null int64\n",
      "fare               891 non-null float64\n",
      "embarked           891 non-null object\n",
      "class              891 non-null object\n",
      "embark_town        891 non-null object\n",
      "alone              891 non-null int64\n",
      "embarked_encode    891 non-null int64\n",
      "dtypes: float64(2), int64(7), object(4)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from acquire import get_titanic_data\n",
    "from prepare import prep_titanic_data\n",
    "\n",
    "df = prep_titanic_data(get_titanic_data())\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.9000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass   age      fare  sibsp  parch\n",
       "60        3  22.0    7.2292      0      0\n",
       "348       3   3.0   15.9000      1      1\n",
       "606       3  30.0    7.8958      0      0\n",
       "195       1  58.0  146.5208      0      0\n",
       "56        2  21.0   10.5000      0      0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True) # handle missing age values\n",
    "\n",
    "X = df[['pclass','age','fare','sibsp','parch']]\n",
    "y = df[['survived']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fit the K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = ['uniform', 'density']\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.76\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[239  54]\n",
      " [ 65 141]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80       293\n",
      "           1       0.72      0.68      0.70       206\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       499\n",
      "   macro avg       0.75      0.75      0.75       499\n",
      "weighted avg       0.76      0.76      0.76       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run through steps 2-4 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.71\n",
      "[[252  41]\n",
      " [103 103]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.78       293\n",
      "           1       0.72      0.50      0.59       206\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       499\n",
      "   macro avg       0.71      0.68      0.68       499\n",
      "weighted avg       0.71      0.71      0.70       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# weights = ['uniform', 'density']\n",
    "knn = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_train)\n",
    "y_pred_proba = knn.predict_proba(X_train)\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Run through setps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.71\n",
      "[[249  44]\n",
      " [100 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.78       293\n",
      "           1       0.71      0.51      0.60       206\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       499\n",
      "   macro avg       0.71      0.68      0.69       499\n",
      "weighted avg       0.71      0.71      0.70       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# weights = ['uniform', 'density']\n",
    "knn = KNeighborsClassifier(n_neighbors=20, weights='uniform')\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_train)\n",
    "y_pred_proba = knn.predict_proba(X_train)\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Save the best model in knn_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_fit = knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN - Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      "species         150 non-null int64\n",
      "sepal_length    150 non-null float64\n",
      "sepal_width     150 non-null float64\n",
      "petal_length    150 non-null float64\n",
      "petal_width     150 non-null float64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 5.9 KB\n"
     ]
    }
   ],
   "source": [
    "# # ignore warnings\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from acquire import get_iris_data\n",
    "from prepare import prep_iris_data\n",
    "\n",
    "df = prep_iris_data(get_iris_data())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.98\n",
      "[[32  0  0]\n",
      " [ 0 39  1]\n",
      " [ 0  1 32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.97      0.97      0.97        40\n",
      "           2       0.97      0.97      0.97        33\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       105\n",
      "   macro avg       0.98      0.98      0.98       105\n",
      "weighted avg       0.98      0.98      0.98       105\n",
      "\n",
      "Accuracy of KNN classifier on test set: 0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "y = df[['species']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "# weights = ['uniform', 'density']\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_train)\n",
    "y_pred_proba = knn.predict_proba(X_train)\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('Accuracy of KNN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test, y_test)))\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.97\n",
      "[[32  0  0]\n",
      " [ 0 39  1]\n",
      " [ 0  2 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.95      0.97      0.96        40\n",
      "           2       0.97      0.94      0.95        33\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       105\n",
      "   macro avg       0.97      0.97      0.97       105\n",
      "weighted avg       0.97      0.97      0.97       105\n",
      "\n",
      "Accuracy of KNN classifier on test set: 0.96\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "y = df[['species']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "# weights = ['uniform', 'density']\n",
    "knn = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_train)\n",
    "y_pred_proba = knn.predict_proba(X_train)\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('Accuracy of KNN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.96\n",
      "[[32  0  0]\n",
      " [ 0 39  1]\n",
      " [ 0  3 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.93      0.97      0.95        40\n",
      "           2       0.97      0.91      0.94        33\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       105\n",
      "   macro avg       0.97      0.96      0.96       105\n",
      "weighted avg       0.96      0.96      0.96       105\n",
      "\n",
      "Accuracy of KNN classifier on test set: 0.91\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "y = df[['species']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "# weights = ['uniform', 'density']\n",
    "knn = KNeighborsClassifier(n_neighbors=20, weights='uniform')\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_train)\n",
    "y_pred_proba = knn.predict_proba(X_train)\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('Accuracy of KNN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest - Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      "passenger_id       891 non-null int64\n",
      "survived           891 non-null int64\n",
      "pclass             891 non-null int64\n",
      "sex                891 non-null object\n",
      "age                714 non-null float64\n",
      "sibsp              891 non-null int64\n",
      "parch              891 non-null int64\n",
      "fare               891 non-null float64\n",
      "embarked           891 non-null object\n",
      "class              891 non-null object\n",
      "embark_town        891 non-null object\n",
      "alone              891 non-null int64\n",
      "embarked_encode    891 non-null int64\n",
      "dtypes: float64(2), int64(7), object(4)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from acquire import get_titanic_data\n",
    "from prepare import prep_titanic_data\n",
    "\n",
    "df = prep_titanic_data(get_titanic_data())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.9000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass   age      fare  sibsp  parch\n",
       "60        3  22.0    7.2292      0      0\n",
       "348       3   3.0   15.9000      1      1\n",
       "606       3  30.0    7.8958      0      0\n",
       "195       1  58.0  146.5208      0      0\n",
       "56        2  21.0   10.5000      0      0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle missing age values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df[['pclass','age','fare','sibsp','parch']]\n",
    "y = df.survived\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_id       0\n",
       "survived           0\n",
       "pclass             0\n",
       "sex                0\n",
       "age                0\n",
       "sibsp              0\n",
       "parch              0\n",
       "fare               0\n",
       "embarked           0\n",
       "class              0\n",
       "embark_town        0\n",
       "alone              0\n",
       "embarked_encode    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=20, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=123, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10439494 0.39013442 0.38148822 0.06701136 0.05697105]\n"
     ]
    }
   ],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf.predict(X_train)\n",
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72104762, 0.27895238],\n",
       "       [0.03      , 0.97      ],\n",
       "       [0.822     , 0.178     ],\n",
       "       [0.04      , 0.96      ],\n",
       "       [0.26666667, 0.73333333],\n",
       "       [0.802     , 0.198     ],\n",
       "       [0.96333333, 0.03666667],\n",
       "       [0.63      , 0.37      ],\n",
       "       [0.79666667, 0.20333333],\n",
       "       [0.74      , 0.26      ]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = rf.predict_proba(X_train)\n",
    "y_pred_proba[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.98\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[291   2]\n",
      " [  6 200]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       293\n",
      "           1       0.99      0.97      0.98       206\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       499\n",
      "   macro avg       0.98      0.98      0.98       499\n",
      "weighted avg       0.98      0.98      0.98       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on TEST set: 0.71\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on TEST set: {:.2f}'\n",
    "     .format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run through steps increasing your min_samples_leaf to 5 and decreasing your max_depth to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=5,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=123, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31756957 0.13479889 0.39019831 0.07086815 0.08656508]\n"
     ]
    }
   ],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.75\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[247  46]\n",
      " [ 79 127]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80       293\n",
      "           1       0.73      0.62      0.67       206\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       499\n",
      "   macro avg       0.75      0.73      0.73       499\n",
      "weighted avg       0.75      0.75      0.75       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "Min Leaf of 1 and Max depth of 20 performed better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Save the best model in forest_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_fit = rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest - Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08980597 0.0198138  0.44366243 0.44671781]\n",
      "Accuracy of random forest classifier on training set: 1.00\n",
      "[[32  0  0]\n",
      " [ 0 40  0]\n",
      " [ 0  0 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       1.00      1.00      1.00        40\n",
      "           2       1.00      1.00      1.00        33\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       105\n",
      "   macro avg       1.00      1.00      1.00       105\n",
      "weighted avg       1.00      1.00      1.00       105\n",
      "\n",
      "Accuracy of random forest classifier on test set: 0.93\n"
     ]
    }
   ],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from acquire import get_titanic_data\n",
    "from prepare import prep_titanic_data\n",
    "\n",
    "df = prep_iris_data(get_iris_data())\n",
    "df.dropna(inplace=True)\n",
    "X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "y = df.species\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=20, \n",
    "                            random_state=123)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "print(rf.feature_importances_)\n",
    "y_pred = rf.predict(X_train)\n",
    "y_pred_proba = rf.predict_proba(X_train)\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "     .format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08647229 0.00786147 0.45520172 0.45046453]\n",
      "Accuracy of random forest classifier on training set: 0.96\n",
      "[[32  0  0]\n",
      " [ 0 37  3]\n",
      " [ 0  1 32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.97      0.93      0.95        40\n",
      "           2       0.91      0.97      0.94        33\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       105\n",
      "   macro avg       0.96      0.96      0.96       105\n",
      "weighted avg       0.96      0.96      0.96       105\n",
      "\n",
      "Accuracy of random forest classifier on test set: 0.96\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=5,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "print(rf.feature_importances_)\n",
    "y_pred = rf.predict(X_train)\n",
    "y_pred_proba = rf.predict_proba(X_train)\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "     .format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on test set: 0.80\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on test set: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Model score on TEST\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
