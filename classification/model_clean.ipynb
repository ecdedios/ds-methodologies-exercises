{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "\n",
    "from graphviz import Graph\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from acquire import get_titanic_data\n",
    "from prepare import prep_titanic_data\n",
    "\n",
    "from acquire import get_iris_data\n",
    "from prepare import prep_iris_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.03183343 -0.00819677  0.01882492 -0.02030296  0.01317287]]\n",
      "Intercept: \n",
      " [0.00230414]\n",
      "Accuracy of the Logistic Regression classifier on        training set (Model Score):        0.6472945891783567\n",
      "[[181 112]\n",
      " [ 64 142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.62      0.67       293\n",
      "           1       0.56      0.69      0.62       206\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       499\n",
      "   macro avg       0.65      0.65      0.65       499\n",
      "weighted avg       0.66      0.65      0.65       499\n",
      "\n",
      "Recall: \t 0.6893203883495146\n",
      "Precision: \t 0.5590551181102362\n",
      "F1: \t\t 0.6241877532298754\n",
      "Support: \t 206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Get and prepare the data\n",
    "df = prep_titanic_data(get_titanic_data())\n",
    "\n",
    "# Handle missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Set the features\n",
    "X = df[['pclass','age','fare','sibsp','parch']]\n",
    "y = df[['survived']]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "\n",
    "# 1. Make\n",
    "logit = LogisticRegression(C=1, class_weight={1:2}, random_state = 123, solver='saga')\n",
    "\n",
    "# 2. Fit\n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "# 3. Do\n",
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)\n",
    "y_pred = logit.predict(X_train)\n",
    "y_pred_proba = logit.predict_proba(X_train)\n",
    "\n",
    "# Model score\n",
    "print(f'Accuracy of the Logistic Regression classifier on\\\n",
    "        training set (Model Score):\\\n",
    "        {logit.score(X_train, y_train)}')\n",
    "\n",
    "# Confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "cm = pd.DataFrame(confusion_matrix(y_train, y_pred),\n",
    "                 columns=['Pred -', 'Pred +'], index=['Actual -', 'Actual +'])\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "# tp = cm.loc['Actual +', 'Pred +']\n",
    "# fn = cm.loc['Actual +', 'Pred -']\n",
    "# fp = cm.loc['Actual -', 'Pred +']\n",
    "# tn = cm.loc['Actual -', 'Pred -']\n",
    "# recall = tp / (tp + fn)\n",
    "# precision = tp / (tp + fp)\n",
    "# f1 = (recall + precision) / 2\n",
    "# support = tp + fn\n",
    "# print(f'Recall: \\t {recall}')\n",
    "# print(f'Precision: \\t {precision}')\n",
    "# print(f'F1: \\t\\t {f1}')\n",
    "# print(f'Support: \\t {support}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
