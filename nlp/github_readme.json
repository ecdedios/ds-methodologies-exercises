[{"readme": "\n\n\n\n        README.md\n      \n\n\nInfluence Texas has launched!  Checkout the live webapp at https://app.influencetexas.com/\nFind more information at https://www.influencetexas.com/\nWelcome & Project Summary\nWelcome! We\u2019re so glad you\u2019ve found your way to INFLUENCE TX. This project was started at ATX Hack for Change June 2-4, 2017 by Amy M. Mosley, a former investigative reporter who was frustrated by a fruitless search for fact-based, unbiased sources for information during the toxic 2016 election cycle. In 2017 all ATX Hack for Change projects were aligned with United Nations Sustainable Development Goals. This project falls under Goal 16: Promote just, peaceful and inclusive societies.\nThe premise is this, Politicians lie.\nAnd usually, they do whatever they get paid to do. You need to know:\nWho is paying them?\nHow are they voting as a result?\nBy linking lawmakers\u2019 campaign finance records to their voting records, taxpayers can track the influence of money in the Texas political process.\nIn this era of political polarization and biased news sources, people are craving information and hard facts. INFLUENCE TX empowers citizens to do their own research and figure who their politicians are really serving.\nWe invite all those who participate in INFLUENCE TX to help us create safe and positive experiences for everyone, while maintaining a robust sense of humor. Please read our CODE_OF_CONDUCT.md and MANIFESTO before you proceed further.\n\"The cornerstone of democracy rests on the foundation of an educated electorate.\" - Thomas Jefferson\n\nPurpose\nInforming the Texas electorate.\nProject Vision\nINFLUENCE TX puts campaign finance records next to voting records so taxpayers can track the influence of money in the Texas state political process. This is the only product people can use to find out who paid off their Texas state politicians and how they voted as a result.\nFor citizens interested in Texas state government who need an unbiased source they can use to determine what their politicians are really doing.\nThis product is a mobile-first responsive web app (with an advanced-user desktop version planned for future releases) that puts campaign finance and voting records in a usable format so citizens can see how money is influencing the political process\nUnlike product like FollowTheMoney.org, which offers no explanation of (1) where they got their data (2) how \u201cfresh\u201d it is (3) matching methodology of associating certain monetary donations with certain industry segments, and also does not offer voting records\nManifesto\nThree ITX team members are in Mozilla Open Leaders Training Program. The principles that guide the INFLUENCE TX mission to provide information that creates transparency in government are those of The Mozilla Manifesto. Principle No. 10 is particularly relevant: \u201cMagnifying the public benefit aspects of the Internet is an important goal, worthy of time, attention and commitment.\u201d\n\nINFLUENCE TX a nonpartisan, open source project devoted to developing a research tool that empowers citizens with varying degrees of technical skill to be their own reporters -- they don\u2019t have to wait for a biased gatekeeper to give them the news.\nINFLUENCE TX will never advocate for or affiliate itself with a political party.\nINFLUENCE TX is an inclusive organization that welcomes people of all political persuasions -- including Democrats, Republicans, and independents.\nWe advocate for curiosity over judgment. We are dedicated to sound research. In so doing, we are courageous and willing to have our own views and opinions challenged by facts and new ways of looking at the world. We are willing to be surprised.\nWe seek greater understanding of those around us.\nWe pledge to value people as human beings and to foster an atmosphere of kindness, cooperation, and understanding.\nA primary goal of INFLUENCE TX is to be inclusive to the largest number of contributors, with the most varied and diverse backgrounds possible.\n\nReason\nVoting drives are nice, but getting uninformed people to cast ballots is not helping anyone. Voters need a quick, user-friendly way to tell who a politician really is.\nWho has the time to search for hours and hours through newspapers and online articles in the (possibly vain) hope of finding unbiased information on each and every candidate?\nVoters need to know:\n\nwhose money has the potential to influence a politician (campaign finance records).\nhow the politician voted (voting records).\n\nBy putting these two pieces of information together in a succinct mobile platform, we can turn uninformed voters into informed voters.\nContributing\nAll participants should read the Influence Texas Code of Conduct prior to engaging with the team and contributing on the product.\n\nView the work needed for our upcoming milestone.\nDevelopment\nFor instructions on getting started with development, go to src/README.rst.\n\n\n", "language": "Python"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nopen-austin.org\nThe Open Austin website\n\nHow to Draft a Blog Post\nDevelopment Instructions\nPlanning\nLicense\n\n\nDevelopment Instructions\n\n(Optional) Install iTerm for a better Command Line App in OS X.\n(Optional) Install oh-my-zsh for a prettier command line interface and easier zsh configuration than bash. - sh -c \"$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"\n\nJekyll requires at least Ruby 2.1 but we recommend Ruby 2.4+\nYou can install a proper version of Ruby via homebrew and rbenv.\nInstall command line tools if you haven't\nxcode-select --install\nInstall Homebrew if you haven't\n/usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"\nInstall rbenv and ruby\nbrew install rbenv ruby-build\nrbenv init\nrbenv install 2.4.2\nrbenv global 2.4.2\nrbenv shell 2.4.2\nInstall Ruby Bundler\n\ngem install bundler\n\nupdate rbenv config\nrbenv rehash\neval \"$(rbenv init -)\nRun all of the above using one command:\ncurl https://gist.githubusercontent.com/DirtyF/5d2bde5c682101b7b5d90708ad333bf3/raw/bbac59647ac66016cf443caf7d48c6ae173ae57f/setup-rbenv.sh | bash\nStart Jekyll\nOnce you've got everything installed, run\nbundle install\n\nThen,\nbundle exec jekyll serve --incremental --watch --trace\n\nThen go to\nhttp://localhost:4000/\n\nInstructions for exporting content from Wordpress\ngem install jekyll-import hpricot open_uri_redirections\nruby -rubygems -e 'require \"jekyll-import\";\n    JekyllImport::Importers::WordpressDotCom.run({\n      \"source\" => \"import/openaustin.wordpress.2015-11-21.xml\",\n      \"no_fetch_images\" => false,\n      \"assets_folder\" => \"assets\"\n    })'\n\nTroubleshooting\n\nif you get permissions errors, run the command again with 'sudo'\n\nsudo <your> <command here>\n\n\nPlanning\nStaging Site: http://open-austin.github.io/\nPlanning & Design\nSitemap\n\nlink to Gliffy\nDesign Docs\n[Design Brief](planning-design/planning_and_analytics/OA Design Brief.pdf?raw=true)\nColors/Typography\nMockups\nHomepage Mockups from 1-Sept\nHigher fidelity Mockup from 24-Aug Meeting ([PDF](planning-design/other_mockups/OA Homepage 1.pdf?raw=true) AND [Sketch](planning-design/other_mockups/OA Homepage 1.sketch?raw=true))\nOriginal Lo-fi Mockup\nRequirements\nLink to functional requirements doc\nAssets/Images\nLinks to potential assets/images\nLicense\nThe code for this repository has been released into the public domain by Open Austin via the Unlicense.\n\n\n", "language": "HTML"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nharris-county-bookings\nA searchable repository which aggregates the daily Harris County Justice Information and Management System 1058\nreports (JIMS 1058) of arrests from the Harris County Sheriff's Office.\nThe latest JIMS 1058 report can be found via the Harris County JIMS site.\nThis information is intended for researchers and non-profits looking to do studies on policing in Harris County.\nIn this public repository, personal information data is removed and the abridged dataset is saved to the\ndata directory. Please see JIMSRecorder#ALL_HEADERS\nfor the latest on which headers are removed. If your research requires the raw data, please contact\nOpen Austin for access to\nopen-austin/harris-county-bookings-raw.\nUsage\nInstall dependencies.\npip install -r requirements.txt\n\nGet today's scrubbed JIMS 1058 report and save it in the data directory.\n./save_today.py\n\nGet today's raw JIMS 1058 report and save it in the raw-data directory.\n./save_today.py --mode raw\n\nGet both today's raw and scrubbed JIMS 1058 report and save them in the appropriate directories.\n./save_today.py --mode both\n\nTo get today's JIMS 1058 report and to save it to GitHub, data.world, or S3, first create\na harris_county_bookings/settings.py file and include your account credentials.\n(See harris_county_bookings/settings_example.py for an example of the contents.) Then run\nsave_today.py with the --commit, --dataset, or --s3 flag.\nThe --mode flag can be used in combination to suit your needs.\nExamples:\n./save_today.py --commit\n./save_today.py --dataset\n./save_today.py --s3\n./save_today.py --commit --dataset --mode raw\n\nLambda Usage\n\nCreate the harris_county_bookings/settings.py file as previously mentioned.\nConfigure AWS credentials via the usual means (i.e. aws configure or environment variables).\nManage the Lambda function.\n\n\nInitial deployment: invoke clean create_lambda\nSubsequent code updates: invoke clean deploy\n\nThe deployed Lambda function will execute ./save_today.py --commit --dataset --mode both.\nTODO\n\ntests\n\nContext\nThis project was started thanks to an\nidea posted Open Austin's project-ideas repo.\nPlease refer tothat for additional context.\nLicense\nThe code for this repository has been released into the public domain by Open Austin via the\nUnlicense.\n\n\n", "language": "Python"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nBallotAPI - Ballots for developers\nNOTE: THIS PROJECT IS UNDER DEVELOPMENT. THE API DOES NOT WORK YET.\nMain website: https://ballotapi.org/\nWhat is BallotAPI?\nBallotAPI exactly what it sounds like: a ballot API. More specifically,\nit is a public domain database and REST API of election and ballot\ninformation in the United States. The goal of this project is to allow\ndevelopers to integrate up-to-date election and ballot information into their\napps and websites.\nThis project is maintained by Open Austin,\na Code for America brigade.\nCurrent Status\n\n Docs - what the API should do (Initial docs done! https://ballotapi.org/docs)\n Prototype - server that follows the docs\n Website - website design/logo/content\n Demo - example app that uses the API\n Testing - automated tests and sanity checks\n Maintenance - apps for maintaining the dataset\n Ops - tools for running/monitoring production\n\nLicense\nProject License\nThis entire project (including all source code, documentation, and ballot data)\nis released into the public domain.\nDependency Licenses\nWhile this project is released into the public domain, it does depend on other\nopen source projects. All dependencies are not included in the project license\nare released under their respective open source licenses.\n\nBootstrap - MIT\nBootstrap.native - MIT\nLeaflet - BSD-2-Clause\nJekyll - MIT\nPython - PSFL\nPsycopg2 - LGPL\nPostgreSQL - PostgreSQL Licence\nPostGIS -  GPLv2\n\nContributions\nWe love all types of contributions!\n\nDevelopment: See the CONTRIBUTING.md\nDonations: Email donate@ballotapi.org\nVolunteering: Email volunteer@ballotapi.org\n\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nIced Coffee\nThis is where we keep track of our brigade managemant activities.\nCheck out our To-Do's on our Waffle.io Issue Board.\n\ud83d\udcdd Sign up to help us out at our next event.\nExpress interest in joining our leadership team.\nAdmin\nLearn about brigades from the Code for America Brigade Playbook v.1\nMembership\n\nSign in to an event become an Open Austin member\nRead our Code of Conduct\nGive us feedback\n\nCommunication\nThe Communication team handles the Open Austin Newsettes, social presense and more.\n\nView issues we need help with | Github issues tagged \"comms\"\nSuggest something to our newsletter | Newsletter planning doc\nJoin us in slack | #comms-Team Slack Invite\n\nView full communications team documentation.\nResources\nWe're an open book, take a look at our expenses so far in Google Sheet or CSV/Needs to be updated\nLook at how we use our resources compared to other Code for America brigades in 2017, 2016, & 2018.\nNon Profit Governance\nHere's a link to our website with info about our bylaws and leadership minutes.\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nData Portal Analysis\nThere's a lot of content on the City of Austin's open data portal. This project is about studying that content so we can make the portal better.\nStatus\n\nWe're currently developing the second release of the Portal Analyzer; previous releases can be found on this page.\nCurrent project goals\nWrite code that grabs specific pieces of information from Austin's public data portal and rearranges it into a format that's useful for analysis.\nNext goals include automated publishing to the City's data portal, so everyone can access and analyze this data.\nWhy we're doing this\nThere are many ways to explore data quality. Improving data quality is a job that's never done.\nCurrent business needs/issues to explore include:\nIdentifiers... How often are departments using unique identifiers for City assets? What is the nature of those identifiers? Where might we benefit from using common identifiers?\nRedundancy... How often are departments publishing the same information within their datasets? Are there any departments publishing about the same topics who might want to collaborate?\nAccessibility... Are we using multiple resources to publish the same information repeatedly for different time periods? (Not ideal for API consumers.) What column labels and descriptions don't match up with their values, and could perhaps use some tuning? How often are schemas changing? Are these changes good or bad for data consumers?\nTable grain... How often are we publishing aggregate information (subtotals and totals) when we could be publishing atomic data? This one is huge!\nQuick Start Guide\nInstallation and Use\nRun the following commands from a terminal:\ngit clone https://github.com/open-austin/data-portal-analysis.git\ncd data-portal-analysis\n\nOptional steps:\n\nIf you will be usng virtualenv, create an environment and activate it before continuing.\nTo run the most recent stable release, see the note about branches below.\n\nThis command will install dependencies:\npip install -r requirements.txt\n\nAfter pip is finished, run the test suite with:\nnosetests -v\n\nFinally, use the folowing command to run the analyzer in online mode; you can replace results.csv with a filename of your choice:\n./PortalAnalyzer.py results.csv\n\nNote: PortalAnalyzer.py also creates a file called portal_analyzer.log that can be used for troubleshooting. Passing either -v or --verbose on the command line will result in a more detailed logfile. Use --help for a complete list of options.\nRegarding branches\nThe master branch always contains stable code that passes the same tests as the most recent release, but it may have patches that were not included in that release. The default branch, develop, contains code that is still being tested and should not be used \"in production.\"\nThe following command can be used to track and checkout master:\ngit checkout -b master origin/master\n\nTo switch back to the development branch, use git checkout develop.\nDocumentation\n\nHow to contribute\nThe easiest way for Python developers to contribute is by fixing problems detected by QuantifiedCode, because the \"learn to fix\" link provides guidelines for resolving each issue. Click on the badge below to get started.\n\nDevelopers can also help by creating enhancements and new features; visit the project board on waffle.io to get an overview of development status.\n\nIf you'd like to contribute but you're not sure how to start, comment on the meta-issue for the current release and one of the project maintainers will be happy to help.\nContributing terms\nWhen you contribute to this project, you are sharing and/or creating content. Please do not contribute content unless you agree with the terms here.\nCredits\nComing soon\nHistory\nA detailed record of significant changes can be found in the changelog\nLicense\nUnlicense\n\n\n", "language": "Python"}, {"readme": "\n\n\n\n        README.md\n      \n\n\n\nTable of Contents\n\nProject Description\nWhat's next?\nDev Getting Started\n\n\ud83d\udc4b\ud83c\udffc Hello!\nWe're Team Budget Party! Our team includes developers, designers, a publisher, a curriculum writer and educators from Open Austin, the Austin Monitor, and Austin ISD.\nWe are interested in the health of our civic fabric and we are excited about the potential for youth inclusion in the decision making process of local government.\nThanks for coming here to learn more!\nProject Description\nBudget Party was built to help people understand and augment a city budget for Austin. It is an interactive app that is best used in context of a \"Budget Party\" event.\nHistorically, Budget party events have 4 parts:\n\nA budget Overview. A quick presentation is given to people that primes them on the city budget, specifically the parts that citizens can influence.\nBudget Party App Use. People get into small teams with neighbors to go through the app and allocate funds to different departments.\nJudging A selection of people with real city budgeting experience judge the submitted budgets and choose a winner based on the night\u2019s criteria.\nPanel Discussion Once judging is done there is an open discussion on budgeting based on the submitted budgets, feasibility, and real world budgeting experience from the panelist/judges.\n\nRead about the history of Budget Party which includes information on the inception of the project and our Mozilla Grant funding.\nWhat's Next\nThe Budget Party team is currently on pause. Budget season in Austin is over for 2017 but we are working to evaluate how best to move forward with the project to be ready for the 2018 budget season.\nGot an idea? Reach out to the team! Community feedback is valuable in helping us evaluate our next steps. How can we make Budget Party more valuable for you?\nContributing\nThis project has received contributions from some wonderful volunteers. We would love to add your name to the list below. Over the course of this project, we have opportunities to help with design, development, QA & testing, writing, and more. To contribute, you can:\n\nReport a bug or request a feature by opening a new issue.\nReview open issues and leave a comment if you'd like to help or if you need more information.\n\nFor more information on how to get invovled check out CONTRIBUTING.md.\nAlso view our list of contributors.\nDev Getting started\nThis project has a dependency on Node and npm. Make sure they are install on your machine by running the following commands:\nnode -v\nnpm -v\nThis should return the version number of your install.\nIf it doesn't Google how to install Node & npm for your operating system.\nMaybe these links could help you?\n\nUbuntu\nMac\n\nOnce you have cloned this repo to you local machine, open the app directory in your Terminal.\ncd app\nInstallation\n\nnpm install\n\nDevelopment\n\nnpm start\nvisit http://localhost:3000 in your browser\n\nBuild\n\nnpm run build\n\nDeploy\n\nnpm run deploy\n\n\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.md\n      \n\n\ncomplaint-map\nMapping and tagging elements of a legal complaint\nThis is an ATX Hack for Change 2018 project to create a visual vocabulary for communicating about the status of a lawsuit by tagging elements of the complaint, such as the allegations and the elements of each claim.\nThe sample data relates to the Democratic National Committee v. Russia complaint filed in the Southern District of New York on April 20. Hopefully that'll be an interesting case to civic technologists, touching on issues like election law and the scope of the Computer Fraud and Abuse Act.\nPossible resources\nSpaCy \u2014 Industrial-Strength Natural Language Processing\nD3.js \u2014 Bring data to life with SVG, Canvas and HTML\nGraphViz\nViz.js \u2014 Graphviz in your browser\n\n\n", "language": "Jupyter Notebook"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nlobbying-in-Austin\nVisualization of Austin lobbyist registrations.\nOur plan is to take lobbyist registration data from data.austintexas.gov, convert it to show lobbying activity by various organizations on different dates, and make a visualization in D3.js.\nThere are probably still significant errors in our modified versions of the dataset. If you need accuracy, please get your data directly from data.austintexas.gov for now.\nDatasets\n\nlobbyistFromCity.csv: This is closest to the dataset provided by data.austintexas.gov\nlobbyistDedupe.csv: An intermediate step created by running csvdedupe to sort the previous dataset into clusters. Useful mainly for replicating our data cleaning process (see lobbyistsDedupe.ipynb).\nlobbyistTimeRange.csv: A list of time ranges when each lobbyist was employed by every client in the dataset.\nlobbyistByClient.csv: A list of how many lobbyists each client employed on every date (but without the lobbyists' names).\n\n\n\n", "language": "Jupyter Notebook"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nPet Alerts\nPart of ATX Hack for Change 2014\nProblem: Currently, real-time online information on lost / found pets is difficult to find and use, prolonging pet and owner separation and taking up valuable shelter space in Austin, a no-kill city.\nProject: Create a tool that periodically scrapes pet recovery postings and saves them to a database that can be searched via a web tool and will push notifications to interested parties.\nDetails\nPet Harbor and the Austin Animal Center are the sole datasources of the app as of now - we are retrieving data by performing regular API requests against the Austin data portal for new found animals, and running constant reconciliations with our database. The feeder is not part of the Rails application (this repository) - instead, the Rails app has an API that provides access to update our database of missing animals, and external scripts are handling the nasty business of scraping external sources. The current Pet Harbor feeder is a Ruby script using soda to access the data.\nNotifications are being sent to subscribers via email and text message for any new animals logged on AAC.\nInstallation\nNOTE: We temporarily discourage the use of vagrant for this project - it's too slow to be feasible.\nLocal\n\nMake sure you have Ruby 2.1.3 installed (RVM or rubyenv make this easy)\nMake sure you have Bundler installed\n$ git clone git@github.com:open-austin/pet-finder.git\n$ bundle install\n$ rake db:migrate\n$ rails server\nVisit localhost:3000 to view the site in the browser.\n\nVagrant\n\n\nMake sure you have VirtualBox installed.\n\n\nMake sure you have vagrant installed.\n\n\n$ git clone git@github.com:open-austin/pet-finder.git\n\n\n$ vagrant up\n\n\nNote that you will likely have to enter your password at some point to enable NFS - this is bypassable by sourceing the following from vagrant's docs:\n  Cmnd_Alias VAGRANT_EXPORTS_ADD = /usr/bin/tee -a /etc/exports\n  Cmnd_Alias VAGRANT_NFSD = /sbin/nfsd restart\n  Cmnd_Alias VAGRANT_EXPORTS_REMOVE = /usr/bin/sed -E -e /*/ d -ibak /etc/exports\n  %admin ALL=(root) NOPASSWD: VAGRANT_EXPORTS_ADD, VAGRANT_NFSD, VAGRANT_EXPORTS_REMOVE\n\n\n\n\n\nVisit localhost:3000 to view the site in the browser.\n\n\nConfiguration\nWe are using Figaro to manage secret configuration settings - all this means for you is that you should create an application.yml file in config/ that looks like the following:\nGMAIL_USERNAME: [working gmail address]\nGMAIL_PASSWORD: [working gmail password]\n\nhttp_username: username\nhttp_password: password\n\naws_key: [request a key]\naws_secret: [request a secret]\ns3_bucket: pet-alert-dev\n\nplivo_auth_id: auth-id\nplivo_auth_token: auth-token\nplivo_number: 1231231234\n\nEmail services\nAll emails are sent from a background service called Sidekiq that will be installed alongside the rest of the gems - however, Sidekiq requires redis in order to function properly.\n\nInstall redis\n$ redis-server\n$ bundle exec sidekiq -q notifier -q default\n\nSMS services\nWe are using Plivo to send SMS messages - if you need to test this locally, you will need to request an auth id and token from us. Generally, this shouldn't be necessary - the message sending part of the app is taken care of.\nContributing\nTo contribute, fork this repo and submit pull requests for merges. All updates should have accompanying tests (we use RSpec), and should ensure that all existing tests are passing. We are still establishing coding standards and practices, so do your best to contribute code that is as consistent as possible with things now.\n\n\n", "language": "Ruby"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nOpen Carry API\nThe goal of this project is to create an API that serves data about business and their stated open carry policy.\nThe idea for this project came from our project-ideas repo.\n\nPlease see the github wiki for this site for anticipated changes and notes\n\n##Libraries, software and other tools used\n\nRuby\nRails\nMinitest\nSQLite3 Database\nRails-api\nGeocoder for distance measurement\n\nMore information in the Gemfile\n##Installation Steps\n\nFork this Repo\nClone this Repo\nRun bundle install\nRun rake db:create\nrails s to start server\n\n##More information\n##Credits and Acknowledgements\nThe database for this project is seeded with data gathered from several dynamic sources online. They are:\n\nmomsdemandaction\naustin360 dining blog\ngunfreebusiness\n\nCrowdsourcing will expand the record set.\n\n\n", "language": "Ruby"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nOpen Austin: Project Ideas\nWant to start an Open Austin project?\nShare your idea with us!\nLooking to jump into an existing project?\n\nJoin an active project\nRevive and direct an abandoned idea\nBrowse all the project ideas\nPractice a specific skill, like design, dev, or data wrangling.\n\nAbout the Open Austin Team\nOpen Austin uses civic tech to improve quality of life. We want to help citizen, government, and nonprofit stakeholders solve problems.\nOpen Austin is an open source organization. We make our projects freely and openly available. GitHub is where we collaborate. There are some really handy tools here, including a feature called Issues. This is where we can break projects into manageable problems for collaborators to solve together.\nWe hope you find what you're looking for, but if you need help, you can email us here!\nThanks for co-creating with us!\nHow To Propose or Discuss Project Ideas\nGitHub Issues work just like any other commenting system on the Internet.\nFirst, you'll need to create an account.\nThen you have two options:\nComment on an existing idea (a.k.a. \"issue\")\nScroll through the issues list first to see if anyone's already thinking the same way! If you see an idea that catches your eye, click on it, read the discussion, and then add your thoughts to the bottom of the discussion thread. If you see the Needs Leadership label, bring it up at a hack night, and if you're up for it you can take the lead on it!\nOr, create a new idea.\nIf you don't see the idea you have in mind, add a new one. You'll need a title and description. Someone from the Open Austin Core Team will respond, likely with some questions or feedback, and assign you to the issue to indicate you are leading the effort.\nHere's a quick video intro on using Github Issues for discussion.\nNext Steps\n\n\nPlease make a status update to your issues at least once a month to keep others informed. If we don't hear from you after some time, we might assume you've moved on and will ask others to take the lead.\n\n\nIf nobody's talking yet, it might be that your idea needs some more fleshing out. We highly recommend thinking through the Civic Tech Canvas as a next step!\n\n\nIf you're willing to be the champion on this project, you should let one of our project leads know. GitHub is the platform we're using to collect and vet ideas and then convert them into active projects. Once a project becomes active, we'll help you set up a repository on the Open Austin GitHub organization so you can start scoping and collaborating. We'll continue to use the Issues feature on your own project repo to flag obstacles, opportunities, and answer questions about that specific project. We will then add the project repo link to your idea issue and close it, indicating your graduation from idea to an active project.\n\n\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nHack Task Aggregator\nWeb application to aggregate tasks across projects that are identified for \"hacking\".\nThe \"Hack Task Aggregator\" is a client (Javascript) application that queries a\ncollection of project repositories, identifies all the tasks marked for \"hacking\",\nand presents a single page with this information.\nWe produced this so that people who were interested in hacking on an Open Austin\n(http://www.open-austin.org/) project could see what's available.\nAt this time, the application only supports the Github issue management system.\nGithub allows you to create custom labels and apply them to issues. We use a\n\"hack\" label across projects for tasks that are available for an interested\nhacker to work on.\nAdd Your Project to Our List\nIf you are an Open Austin member and have a project to add to this list, just clone\nthis project, add your project to the \"project-defs.json\" file and send out a\npull request.\nPlease be sure to test first! This JSON file is very brittle, and the app will\nfail if you introduce any problems.\nSteal this App\nThis app should be very portable. The files you'll want to edit are:\n\nindex.html\nproject-defs.json\nassets/hack-task-aggregator.css (if you wish to re-style)\n\nYou should not have to edit \"hack-task-aggregator.js\". If you do, please send\nus a pull request with a fix to address your portability concerns.\nProblem: API Rate Limit Exceeded\nGithub rate limits the number of queries an anonymous user can make. This should\nnot be a problem in normal use. This could easily become a problem during development.\nThis app has a feature that allows you to specify a Github access token,\nto provide an extended query limit.\nFirst, you will need to get an access token by logging into your Github account\nand going to:\nAccount Settings -> Applications -> Personal API Access Tokens\n\nOnce you have your token, specify it in the request with a \"_T\" parameter:\n.../index.html?_T=856e3ee345aa271506d1dcb33d67c9363726ceba\n\nProblem: Failure when running Google Chrome local\nTypically, in development, you will simply open \"index.html\" as a local file\nwith your web browser. If you do this with Google Chrome you may get an error.\nIf you open up the Javascript console, you will see the message:\nFailed to load resource: Origin null is not allowed by Access-Control-Allow-Origin. \n\nThat's a known bug with Chrome, when it tries to use the jQuery $.getJSON() operation\non a local file.\nFortunately, there is an easy workaround. Just start Chrome with the\n\"--allow-file-access-from-files\" option.\nCredits\nPrimary author is Chip Rosenthal chip@unicom.com.\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.txt\n      \n\n\nThis site contains data published by Open Austin prior to 2015. More\nrecent datasets can be found on Open Austin's page on data.world:\n\nhttps://data.world/openaustin\n\nTypically this data is derived from government information, converted\nor processed to some form more amenable for public use.\n\nThe source to this repository is here:\n\nhttps://github.com/open-austin/data-open-austin-org\n\nIf you are a github user, you can open issues or submit changes (pull\nrequests) for publication.\n\n\n", "language": "Ruby"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nCivic Project\nThis project contains data on civic projects by Open Austin members. This is\ninactive, but see the current list on the projects page of the Open Austin\nwebsite.\nprojects Directory\nThe projects directory contains descriptions of the projects, one file\nper project. If you wish to add a project to the directory or update\ninformation on an existing project, either:\n\nsend us a pull request\nopen an issue.\n\nSee the template file for the expected\nformat of a project description.\nSee the Schema.md file for a description of the\nproject fields.\npub Directory\nContains documents produced from the project descriptions.\n\ncfapi.csv - A data feed in the CFAPI format.\nprojects.htincl - An HTML fragment that can be included in a web page.\n\nRequirements are a recent a ruby interpreter and the bundler gem.\nTo setup, run:\nbundle install\n\nTo generate the documents, run:\nrake\n\nData Feed\nThe offical data feed, produced by this project, is hosted at http://data.open-austin.org/Civic_Project/\nWe encourage republication and distribution of this information.\nSummary description for the data feed:\n\nProjects developed by the community and published by Open Austin (http://www.open-austin.org), a volunteer community group that develops civic applications and tools for Austin residents. This list is produced by the Open Austin \"Civic Project\" tool, available at https://github.com/open-austin/Civic_Project\n\n\n\n", "language": "Ruby"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nCity of Austin Construction Permits\nA searchable database of construction permits issued by the City of Austin since 1980.\nData is scraped from http://www.austintexas.gov/oss_permits/permit_report.cfm on a daily basis.\n\u2139\ufe0f The City of Austin has started publishing permits to their open data portal at https://data.austintexas.gov/Permitting/Building-Permits/q7kv-7293.\nUsage\nInstall the requirements:\npip install -r requirements.txt\n\nSet up a secrets file (permits/secrets.py):\nGITHUB_AUTH=<github auth key>\nMAPZEN_API_KEY=<mapzen API key>\n\nGet today's construction permits and store them in the data directory:\npython permits/permits.py\n\nRun the tests:\nnosetests\n\nDeploy to AWS Lambda:\n./lambda.sh\n\nScheduled\nTwice a day an AWS lambda job runs permits.lambda_handler.\nIt fetches yesterday's permits, geocodes the addresses, and then uses the GitHub API to commit the data to this repo. This code is Python 2 because is run on AWS Lambda. Another side effect of being a lambda is we're trying to avoid dependencies with C extensions like pandas.\nLicense\nThe code for this repository has been released into the public domain by Open Austin via the Unlicense.\nCreated by @spatialaustin and @luqmaan.\n\n\n", "language": "Python"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nawesome-austin \nA collection of awesome Austin civic tech projects\nHave something to add or change? Open a pull request or issue.\n\nTable of Contents\n\nData\nApps\nVisualizations\nMeetups\nCity of Austin on GitHub\n\nData\n\nCity of Austin Data Portal\nState of Texas Open Data Portal\nOpen Data Census of Austin\nTNRIS Data Search & Download (Texas Natural Resources Information System)\n\nApps\n\nInstabus\nDadnab\nATXplorer\nAustin 311\n2017 Texas State Water Plan\nAustin Reuse Directory\n\nVisualizations\n\nSpatial Austin\nAustin's Atlas\nEncoding Pixels\nCity Wellness Atlas\nAustin Agenda Map\nCommute.ly - Traffic forecasting app that uses live and historical traffic data to calculate real-time commute predictions.\nOpen Carry Austin by Megan Vo\nIs the Lake Full Yet?\nyouarehere.cc\n\nMeetups\n\nOpen Austin\nMaptime ATX\n\nCity of Austin on GitHub\n\nCity of Austin\nAustin Code Department\n\nLicense\n\nTo the extent possible under law, Open Austin has waived all copyright and related or neighboring rights to this work.\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nGreenBelts\nInteractive web map app to chat and share geo-tagged content about local Austin green spaces.\n\n\n", "language": "CSS"}, {"readme": "\n\n\n\n        README.md\n      \n\n\natx-restaurant-scores\nApp to query Austin restaurant scores dataset on data.austintexas.gov.\n\n\n", "language": "HTML"}, {"readme": "\n\n\n\n        README.md\n      \n\n\n\n\n\n\nPartnering Organizations\n\nMozilla Hive Austin\nAustin Monitor (Capital of Texas Media Foundation)\nNucleus Learning Network\nOpen Austin\nCivic Party Software\n\nProject Purpose\nHelp educators and teens evaluate online news for credibility and trust to strengthen their communities\u2019 resilience to Fake News.\nA grant from Mozilla supports the development of three interactive web literacy lessons and web apps to facilitate learning.\nRoadmap\nOur Work\nOur team has created curriculum for three units and has developed a web app version of Legit-o-Meter.\nWe participated in Misinfo Con hosted at the MIT Media Lab. Here are a couple blog posts from Michael & Sarah about our take-aways.\nSarah also participated in a webinar hosted by EducatorInnovator.org with other media literacy and education advocates on \"Media Literacy Tools to Comprehend & Critique Fake News\"\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/1b-O_e_GhHM\" frameborder=\"0\" allowfullscreen></iframe>\n\nOne of our technical contributors, Rally Jinx, demo'd an early prototype of our Legit-o-Meter Learning App.\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/GgsyTPkTsf4\" frameborder=\"0\" allowfullscreen></iframe>\n\nMilestones\n\n8/7 - 8/8/17: AISD Social Studies + Language Arts\n7/1/17: Identify summer beta testing opportunities\n6/1/17: Finalized curriculum for Units 2 & 3\n5/15/17: Legit-o-Meter v0 target launch for beta testing & Curriculum Due\n4/17/17: Legit-o-Meter v0 target for soft launch for teacher feedback\n4/4/17: Team Check-in\nMarch 29, 2017: Unit 2 Curriculum Deadline\nMarch 15, 2017: Curriculum (Units 2 & 3) Review draft due\nMarch 17, 2017: Team IRL Meeting/Brainstorm\nMarch 6, 2017: Team catch up post-misinfocon\nFeb 24-26, 2017: Misinfo Con\n\nSaturday Discussion Notes\nSunday Wireframes for Legit-o-Meter\n\nMockingbird Link\nNotes \n\n\nSunday Presentation Slides\nList of other MisinfoCon presentations\n\n\nFeb 23, 2017: Drafts notes for Lessons 2 & 3\nFeb 17, 2017: Draft product spec and curriculum for Lesson 1 (Legit-o-Meter) complete\n\nLesson Plan & Worksheet\nWeb App Product Brief\n\n\nFeb 9, 2017: Fake the News team met for brainstorming on the three lesson. Sarah (Nucleus Learning Network) is tasked with creating a Curriculum Outline Draft and Mateo (Open Austin) is tasked with creating a Design Brief for the Legit-o-Meter web app.\n\nThe Lessons\nThese lessons empower students with valuable news literacy skills that they can use to recognize, evaluate, and combat fake news and misinformation.\nLesson #1: Legit-o-Meter\nThe goal of Lesson 1 is to give students the tools to examine a web article's credibility. The Mission:FakeNews team will develop a web app version of the Kraken the Code Web Literacy Exercise.\nLesson #2: Rewriting History\nThe goal of Lesson 2 is to help students better understand how fake new is produced and how it is spread. Students will have the opportunity to deconstruct fake news and to explore the techniques people use to create fake news, and the consequences of those techniques.\nLesson #3: Run the Presses\nThe goal of the Lesson 3 is to put students in the editor\u2019s chair and give them a chance to make decisions common in news organizations, and to experience the consequences of those decisions. With this lesson, students will gain a deeper understanding of how fake news fits in a broader news and information ecosystem.\nContact\n\nAshley Fisher, Austin Monitor\nSarah Morris, Nucleus Learning Network\nMateo Clarke, Open Austin & Civic Party Software\n\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nconsumer-protection\nVisualizations of Consumer Financial Protection Data\nhttps://github.com/open-austin/project-ideas/issues/107\n\n\n", "language": "HTML"}, {"readme": "\n\n\n\n        README.md\n      \n\n\ntransitime-db\nhttp://transitime-host.cloudapp.net/api/v1/key/f18a8240/agency/cap-metro/command/predictions?rs=803%7C4830\nThings to make transitime go:\n\nUbuntu\nsudo apt-get install git\ngit clone https://github.com/walkeriniraq/transitime-db.git\ncurl -sSL https://get.docker.com/ | sh  (i.e. install docker)\n./go.sh\n\nThe go script will build the transitime container (takes a long time), start the postgres db, create the tables,\npush the cap metro data into the db, create a default API key (f18a8240) and then start the server, connecting\nit to the server's port 80.\nIf you want to run an instance of the transitime app, you can call:\n./run_to_bash.sh\n\n\n", "language": "Shell"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nRestaurant-Health-Inspection-Score-Prediction\nWhat problem are we trying to solve?\nHealth inspectors currently pick restaurants to inspect randomly. Using ML, we can predict restaurants most at risk for failing a health inspection. Once these predictions have been made, Austin Department of Public Health staff can use these predictions to prioritize inspections.\nWho will benefit (directly and indirectly) from this project?\nAustin Community will be more assured that the food they eat at any restaurant is safe. Restaurant owners will benefit because this system could also be used as a warning/forecasting system. City health inspectors will save time by focusing on only the most at risk restaurants, and can spend more time on other issues if neccesary.\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        readme.md\n      \n\n\nGitHub and Government \n\nGather, curate, and feature stories of people using GitHub as part of their open government innovations.\nThe site is open source (here's all the code!) and is a tool for and by the community.\nSubmit issues and pull requests for stories, site ideas or copy edits.\nGoals\n\nShare stories of real world experiences using GitHub in open Government\nDemystify open source terminology\nShowcase the community using GitHub to promote connections and sharing between individuals and organizations.\nMake getting started with GitHub easier\n\nUnder the Hood\nThis site is made with Jekyll, an open source static site generator. This means the Jekyll program takes the content we want to be on the site and turns them into HTML files ready to be hosted somewhere. Awesomely, GitHub provides free web hosting for repositories, called GitHub Pages, and that's how this site is hosted. The content for the site is on a branch named gh-pages.\nContributing\nFix/Edit Content\nIf you see an error or a place where content should be updated or improved, just fork this repository to your account, make the change you'd like and then submit a pull request. If you're not able to make the change, file an issue.\nAdd Organization\nIf you know of an GitHub organization that should be added to the organization list that generates the matrix of avatars on the Community page: fork this repository, open the _data/civic_hackers.yml, _data/governments.yml, or_data/research.yml file and add it to the appropriate section of the list in the format being used. Commit your change and submit a pull request to us!\n\nTo Set up Locally\nYou can take all the files of this site and run them just on your computer as if it were live online, only it's just on your machine.\nRequirements\n\nJekyll\nRuby\nGit\n\nIf you have installed GitHub Desktop, Git was also installed automatically.\nTo copy the repository's files from here onto your computer and to view and serve those files locally, at your computer's command line type:\ngit clone https://github.com/github/government.github.com.git\ncd government.github.com\nscript/bootstrap\nscript/server\nOpen http://localhost:4000 in your browser\n\nDon't see what you're looking for? Create an issue, we'll do our best to help you out.\n\n\n", "language": "HTML"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nsporkability \ud83e\udd44 \ud83c\udf74\nBest practices for making projects easy to fork. The most important thing you can do is simplify your projects as much as possible. This repository was created as part of an unconference at the Code for America 2015 Summit.\nHave anything to add? Fork this repo and open a pull request.\nThis repo consists of three parts:\n\nGuidelines\nExamples of projects that do a good job making themselves easy to fork\nREADME Template\n\nGuidelines\nSimplify your app as much as possible\n\nReduce the number of dependencies\n\nDo you really need mongo and memcached?\nDo you even need a server?\nCan your app just be static HTML + JS files hosted on GitHub Pages?\n\n\nUse simple, easy-to-deploy technology\n\nTools like Travis CI make deployment public. Anybody can look at the build history and figure out how things are built.\n\n\nDeploy-This buttons\n\nDeploy to Heroku button\n\n\n\nPut yourself in your forker\u2019s shoes\n\nInline documentation, explain your thinking.\nUser Context. Anything to better understand the intended users, uses, usage.\n\nLicenses and Copyright\n\n Choose a license and add it to your repo. ChooseALicense.com can help you choose a license. We recommend dedicating your work to the public domain. Why? The MIT, GPL, and other popular licenses don't answer the question of copyright.\n Don't put copyright 2015 John, Jane, Bob, etc. on every page (or even anywhere in the app). As somebody forking the repo, I don't want to put your name on every page. Will you be offended that I'm removing yourname?\n\nAdmit your mistakes\n\n Are you unhappy with the architecture or the code of your app? Say so in the README or an issue (and explain why). People trying to fork your app may encounter some of these same problems and have solutions. Or they may just give up.\n\nTalk about your data\n\n What is the minimum amount of data needed to get the project running?\n List all the data the app uses, where it comes from, and how it is used.\n Sample data, please.\n Tests and test data, if you used them.\n\nREADME.md\nSee the README-template.md.\n\n Brief description of what the project does and why it exists. Explain why would someone else care.\n Include screenshots of the project so people can see the project in action without figuring out how to use it.\n Include a link to the project.\n Specify a maintainer.\n\nINSTALL.md\nBy default, include installation instructions in the README. Consider moving the instructions to a INSTALL.md if the instructions are very long and distract from the rest of the README.\n\n Use your languages package management tools. Avoid asking people to install them by hand. Be sure to use very specific version numbers (6.6.6 is much better than just 6).\n\nPython: requirements.txt\nJavaScript: package.json\nRuby: Gemfile\nGo:  (Check in your dependencies, I guess)\n\n\n List dependencies that have to be manually installed. Link to useful guides on setting them up. Examples include Postgres, ...\n Test your installation and deployment instructions on a clean machine.\n CHANGELOG.md\n\"It is a good idea to keep a changelog. http://keepachangelog.com (is a project on GitHub). \"\n\nSee https://github.com/cfpb/qu and https://github.com/cfpb/hmda-explorer\nSome Inspiration: http://keepachangelog.com/\n\n\n\nBe easy to contact\n\nAnswer/use GitHub issues\nAdd an email to the README, or add emails to your GitHub profile\nSpecify a maintainer, and make sure the maintainer has an easy to find email\nIf your brigade or project has a Slack channel, add a link to it.\n\nCode Style\n\nFormat code consistently and follow a popular styleguide.\n\nJavaScript\n\nJS Standard Style\nAirbnb JavaScript Style Guide\nESLint\n\n\nPython\n\nPEP8\npyflakes\n\n\nGo\n\ngofmt\n\n\n\n\n\nRepo Metadata\n\n\n Fill out the Description on GitHub\n Fill out the URL on GitHub\n\nConfiguration\n\n Keep your city specific configuration in one file\n\nFor example, if your app has a map with some initial coordinates, store those initial coordinates in a config file instead of making them difficult to find.\n\n\n Move other hard-coded values to a settings file.\n\nExamples\nSome apps that have been easy to fork:\n\nCutePetsBot - Forked over 40 times. This project did a great job of explaining its benefit and being simple.\ncodeforamerica/bizfriendly-web - For its use of the beginner friendly label\n\nREADME Template\n# Project Name\n\nTODO: Write a project description.\n\nTODO: Link to a demo, project homepage, or whatever makes sense\n\nTODO: Include a screenshot, wireframe or something visual other than a logo.\n\nTODO: Sell your project.\n\nTODO: Include a logo if your project has one.\n\nTODO: Include any badges/shields if applicable. http://shields.io/\n\n## Getting started\n\nTODO: Explain how to use your project\n\n## Installation\n\nTODO: Describe the installation process\n\n## Contributing\n\nTODO: Explain how you would like people to contribute:\n\n- Link to GitHub Issues if you use them\n- List some things you would like to do with the project if you had more time\n\n## History\n\nTODO: Write history\n\n## Credits\n\nTODO: Write credits\n\n## License\n\nTODO: Write license\n\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nOpen Data Progress Report\nOverview\nOpen Austin believes 21st century governance can work for the people \ud83d\udcaa. We build open source technology and organize volunteers to envision government services made simple, effective, and accessible.\nInformation is a service of our government. Data is a service of our government. (See FOIA)\nAccessible data promotes better decisions and planning... And its fun to geek out on \ud83d\udc53.\nAustin's City Manager kicked off an \"Open Data Initiative 2.0\" in April 2015 (see the Memo). Every city department was asked to:\n\ndesignate an open data liaison\nconduct a data inventory\nsubmit an open data participation plan\npublish at least three new datasets to the City\u2019s open data portal.\n\nThe initial 90-day sprint has concluded and published are the results.\nSetup\ngit clone git@github.com:open-austin/open-data-progress-report.git\nRunning locally\nNo server necessary, just drag index.html into a browser and let javascript do the rest.\nTeam\nThis project includes contributions from:\n\n@sharlalikesyou\n@luqmaan\n@carissamelanson\n@mateoclarke\n\nErrors / Bugs\nIf something isn't quite right, let us know. Or if you'd like to try to fix it yourself but you're not quite sure how, just open an issue and ask.\nPull Requests\nWe \u2764\ufe0f Pull Requests.\nWe could use some help with these things.\nContributing\nReleased to the public domain under the Unlicense by Open Austin, 2015.\nUnlicense\nBy contributing to this project you agree to the following:\nI dedicate any and all copyright interest in this software to the public domain. I make this dedication for the benefit of the public at large and to the detriment of my heirs and successors. I intend this dedication to be an overt act of relinquishment in perpetuity of all present and future rights to this software under copyright law.\nFor more information, see http://unlicense.org/.\n\n\n", "language": "HTML"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nAustin Creeks Water Quality\nThe problem:\nIt is hard to know when swimming spots and other recreational areas are dangerous to health because of bacteria or other safety hazards.\nHere is a link to the original project proposal.\nThis is an infant project.\nCreate an issue if you have ideas and comment on any open issues if you have interest in contributing.\nPotential Application Architecture\nThese smaller pieces could be seperate services or part of one application that does the whole thing. Here are some ideas:\n\nAn analyzer/scoring program that runs through the public data and scores each site/creek. It looks like that might be hard to do that as you pointed out the measurement type for E Coli counts in varying units. I'm thinking what would be nice is if the program was able to automatically:\n\ndownload the input data from the City's data portal\nevaluate each site and/or creek and give it some score or color assignment based on the safety of the water.\nprint out the scores in a new table\n\n\nAn API that you can query for each creek's score.\nA twitter bot that queries the API and runs logic based on each creek and decides what to tweet out.\nA web app/visualization that lets you see the results of the output table based on a map of the waterways and/or a list of creeks you can filter/sort.\n\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nbudgetparty-landing\nA landing page and hub for all things budget party!\nUsage\nnpm install budgetparty-landing\n\nJSX\nimport Landing from 'budgetparty-landing';\n\n...\n\n<Landing contributorsURL='https://api.github.com/repos/open-austin/budgetparty/contributors'/>\n\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nrestroom-map\n\nThis is based on a boilerplate mobile hybrid app for I/O with maps, called mobile-map-io. The idea is that many civic apps have to do with reporting things as people see them. That means people are mobile, they're talking about things that are mappable, and they're reporting those things and getting those reports (I/O). These were the three key things that drove this project, in addition to the frequent reinvention of this sort of generic app infrastructure ad-hoc.\nNow, if you want to make an app for your neighbors to report broken streetlights, fork this repo. If you want to make an app for your community to report code violations, fork this repo. If you want to make an app to post all your favorite resturants, fork this repo. You can do all those things out of the box. If you want to make this into something slightly different, like a system that connects businesses and hungry people, follow these instructions to start developing:\n\nRun npm install\nRun bower install\nRename .env.example to just .env and add your secret keys/config\nImport api/reports.sql\nRun npm start\nCheck out the CONTRIBUTING.md file for how to contribute back\n\nThis project\nThis software is licensed to Andrew Nelson, see the LICENSE file. If you would like an exception to this license for commercial/proprietary derivative work, please email me.\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nHackpad\nThis repo contains Open Austin Hackpad documents. Hackpad was acquired by Dropbox and then shut down in favor of the Dropbox Paper product. These Markdown files of our documentation and Hack Night agendas are stored in here for archival purposes.\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nprojects-bot\nA bot that helps run project management tasks\nUsing it\n\npip install -r requirements.txt\nCreate a Github personal access token with public_repo scope\nexport GITHUB_TOKEN=[your token]\npython bot.py\n\n\nTo show expected results without action, add the test argument: python bot.py test\n\n\n\n", "language": "Python"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nliberate-appraisal-data\nJoin the ongoing discussion with Open Austin on Slack: http://slack.open-austin.org/\nLiberate Appraisal Data is an effort to open up the Travis County Appraisal District (TCAD) appraisal roll data. The annual appraisal roll consists of valuations of every parcel in the county, and includes details about the age and square footage of property improvements, the size and value of lots, jurisdictional taxing authorities, and much more.\nWe are asking TCAD to make the data available in an open, usable format. Key issues with the current data delivery process are as follows:\n\n\nTo obtain the appraisal roll data citizens must pay $80 per appraisal year. Electronic records are available dating back to 2007.\n\n\nThe data are delivered to citizens in an MS database. This is an arcane, proprietary format that requires special software to view.\n\n\nTCAD's own documentation explicitly states that some of the data are not available at all (even with purchase), due to the limitations of the MS Access format.\n\n\nOther entities (including the City of Austin) have managed to obtain copies of the data in a format other than MS Access, yet the TCAD records office insists that the data are exclusively available in the MS Access format.\n\n\nNeighboring appraisal districts have managed to provide this data for free, in an open format. For example, WCAD: http://www.wcad.org/public-data/downloads?id=343\u2028\n\n\nWe (Open Austin) have proposed a few solutions:\n\n\nPublish the appraisal roll data on our own website for the public to download.\n\n\nTCAD could partner with the City of Austin to have the data published on the city\u2019s open data portal. I am a City of Austin employee and would be happy to connect TCAD staff with the City\u2019s Open Data Team.\n\n\nWe communicated these issues to TCAD Board of Directors chairperson Dick Lavine and the Chief Appraiser's executive assistant on April 10, 2017. Although Dick Lavine has expressed an interest in working with us, we have so far been unable to set up a follow-up meeting or get any response from the Chief Appraiser.\nThe obvious next step is to attend a TCAD board meeting, but unfortunately these take place monthly on a weekday in an inaccessible part of town. Another approach would be to raise money to buy all the data, reformat it, and host it.\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nBrigades and Poltical Action\nCode for America has gotten a number of questions about how Brigades should approach political activism given the current political situation in this country.\nThe short answer is: People should always  do what they feel they need to do to be an actively engaged citizen. The tricky part is what\u2019s advisable to do in the name of your Brigade, which is technically a program of Code for America. As a nonprofit nonpartisan organization, the IRS puts certain rules in place that limit what we can and can\u2019t do. We\u2019ve listed a few below.\nTo be clear, you can always speak or act on your own behalf, as long as you\u2019re not representing your Brigade or Code for America.\nThings that your Brigade can do:\n\nPublicly comment and educate the general public and elected officials on key issues of importance to your organization.\nAdvocate for or against specific public policies by speaking out on decisions made by government agencies, executives, or courts.\nCall, write, and meet with elected officials to support or oppose specific pieces of legislation.\nSponsor and distribute nonpartisan voter guides.\nSurvey candidates and report where they stand on the survey.\n\nThings that Brigades can not do:\n\nThey can not endorse or oppose candidates who are running for public office.\nThey can not advise members of your brigade chapter or the public at large, directly or indirectly, to vote for or against specific candidates or political parties.\nThey can not make financial contributions to candidates.\nThey can not make in-kind contributions (including use of Brigade infrastructure) to political campaigns. (They can\u2019t eat food meant for Brigade actions)\nThey can not collect money on behalf of, or provide in-kind services, to a candidate.\nThey can not create political action committees.\nThey can not distribute or display campaign literature or partisan voter guides.\n\nTo reiterate; you can totally do these things personally, as long as you\u2019re not acting as your Brigade or as Code for America when you do so.\nWhen to say yes and when to say no\nSome good questions to ask when faced with a question about whether to participate:\n\nWill this move my Brigade\u2019s goals forward??  There\u2019s nothing wrong with going \u201cWe\u2019d love to march, but aren't equipped to organize a march. Are you connected with X org?\u201d OR \u201cWe can\u2019t lead it, but we\u2019ll let our members know about it.\u201d\nIs my Brigade equipped to respond appropriately? Do you have the resources? Do you and your volunteers have time?\nIs there another organization already doing this work? Can you partner with them or direct your members their way?\nDoes this align with my Brigade\u2019s values?\nEvery Brigade is different. Your values should reflect your membership. It\u2019s a judgement call that your leadership team has to make.\n\nAll systems go? \n\nRemember to keep your Brigade\u2019s  \u2018voice\u2019 steady and loud\nWhen we say voice, we mean the tone and demeanor of your Brigade\u2019s outbound communications. Words matter. Stay Positive: Code for America has always been about taking an active role in government to use our talents in a positive way. We\u2019re for America not against a person who just happens to hold high office.\nThis might mean re-wording language for certain calls to action. \u201cSave the data\u201d vs \u201cStop the deletion of data\u201d\nThis will also help to avoid violating our 501(c)3 by not being against any particular candidate.\nGovernment agencies are our partners\nRemember, there is more than one level of government.\nA fan of your city? Reiterate a desire to help.\nThe greatest office in a democracy is that of the citizen.\nPeople want to be involved; your Brigade gives them one of many paths where they can do that.\nReiterate your Brigade values early and often\n\nYour Brigade values are what makes you, you. While you may not be able to use the Brigade twitter account to directly lobby - you can use it as an opportunity to say \u201cThis is who we are and this is what we value.\u201d You can always switch to your personal accounts when you want to get more partisan or forceful.\nWhat are good actions to take as Brigades? \n\nSaving open government data to the Internet Archive\nBrigade members have expertise on open data\nIt matches your mission\nIt\u2019s nonpartisan\nPartner with organizations to elevate voices from the community on various topics that matter to your members, such as   encryption, SMS messaging, government 101, or other aspects of governing. Your members may have an interest in learning more about a current newsworthy topic. Invite a speaker to your hacknight to share their knowledge. Being a civic technologists means knowing both sides of the house.\nKeep calm and continue hacking\nYour Brigade already makes your city stronger. You provide a space for people to engage with each other and leverage their technology skills to help their community. Building an app that gives people information about a law or government service.\n\nWhen you need a different type of superhero \nNot everyone can be Batman. In fact, everyone trying to be Batman never turns out well. When looking at our current political climate and the challenges facing our cities,  it\u2019s obvious that we\u2019re going to need the whole Justice League.\nIf you get a call to action (or want to take actions) that doesn\u2019t sync up with the Brigade mission here are some places where you can volunteer or refer others too.\n\nTake off the track jacket and pick up a clipboard\nYes, you could run for office. We know you love your city and your country. At least consider it.\nVolunteer for a campaign\nJoin a politically active meetup\nMarch and protest\nCall your elected officials\nContribute and volunteer for nonprofits doing good work\n\nAs we get real world examples, we'll add these to the list. As always, if you have any questions please email christopher@codeforamerica.org\nThe Brigade Team & the National Advisory Council\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\ncheatsheet-basedef\na repo for our git & BASEDEF cheatsheet\n\n\nThanks to CodeNewbies for sharing their awesome idea & design! & Shoutout to Begriffs for coming up with BASEDEF!\nNot sure what to contribute? BASEDEF.\nBlog\nWhen you stumble upon a project written by someone else (your coworker, say) you tend to see a clear high-level overview and this makes you the perfect person to write an introductory blog post explaining the project.\nApply\nThe best thing for a new tool is to be put to use. Apply a project to one of your own.\nSuggest\nFollow a project\u2019s documentation and see if you can achieve a small victory in less than 5 minutes. Tell the maintainer how it went & what was confusing.\nExtend\nAdd a new feature, either of your own invention or inspired by a feature request on github.\nDocument\nWrite a separate set of documents or improve error messaging. Skews toward technical writing.\nEvangelize\nEmail it, tweet it, submit it to other publications. Just make sure to check with the maintainer, they may prefer to fix problems before recruiting users.\nFix\nFix specific bugs or improve the general process of project development. Includes adding a test suite, enabling continuous integration, or using static code analyzers.\nRead more about BASEDEF at begriffs.com\nCome BASEDEF with us at Open Austin.\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nTexas Appleseed\nThis project orginated from this proposal.\nNow the mapping component of this project lives at https://github.com/txappleseed/txappleseedmap\nLicense\nReleased to the public domain under the Unlicense by Open Austin, 2015.\nContributing\nPlease see CONTRIBUTING.md.\nData\nratioDistrict.csv contains some data about disparities in punishments for various groups and school districts, to be imported into the Leaflet school district map. The column names that we were planning to map are in this format:\nratio (ECO. DISADV.|SPEC. ED.|BLACK OR AFRICAN AMERICAN|HISPANIC/LATINO|WHITE|AMERICAN INDIAN OR ALASKA NAT|ASIAN|NATIVE HAWAIIAN/OTHER PACIFIC|TWO OR MORE RACES) (EXPULSION ACTIONS|IN SCHOOL SUSPENSIONS|OUT OF SCHOOL SUSPENSIONS|DAEP PLACEMENTS) vs average\n\nThat means the map will need 36 settings (9 groups times 4 punishments) to show all the data we want to display. Here's the Gist of the process used to make ratioDistrict.csv.\n\n\n", "language": "Python"}, {"readme": "\n\n\n\n        README.md\n      \n\n\n\nOpen Austin - Breakout Groups\nEvery hack night at Open Austin, we break out into topic-specific working and learning groups led by regular facilitators to guide conversations, answer questions, and build teams for civic apps. The groups are split into two types: working groups and learning groups.\nThese groups change from week to week, with some lasting just a single night to others progressing over several months. To keep track of these fluctuating groups, we use GitHub issues to open, close and update groups over time.\nYou can see a list of highled projects on the Open Austin page, or in the issues list for this GitHub repository.\nTODO: Make available a list of active projects using Github API (EX: https://chihacknight.org/breakouts.html)\nHow do I add a group to the list?\n\nCreate a GitHub account if you don't already have one: https://github.com/join\nOpen a new GitHub Issue in this repository: https://github.com/open-austin/breakout-groups/issues/new\nSet the title of your issue to the name of your breakout, and fill out the description template in the body. We will add the appropriate labels to it.\n\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nRecycling-atx \u267b\ufe0f\nShows you which buildings in Austin recycle and which ones do not.\nThis is an open-source project through Open-Austin.\nThis is a fork of https://github.com/open-city/recycling.\nDeveloping locally\n\nClone this repo\nnpm install - Install dependencies\ngulp build - Build javascript and css assets\ngulp webserver - Spin up a local webserver\ngulp deploy-gh-pages - Ship it! \n\nGoals for this fork are to build:\n\nREST API that can be hosted easily on more than just Heroku. This means:\n\nNo Mongo dependency. Use a relational database like Postgres (or maybe GitHub pages).\n\nNo memcached dependency. We can figure out scaling later.\n\nhttps://github.com/open-austin/recycling-bin/issues/1\nFrontend that consumes the API. It should be just static files that can be hosted on GitHub pages.\n\n\n\n\n\n\n\nPurpose of this fork\nThis repo is a front end component that consumes the API provided by https://github.com/open-austin/recycling-bin\nResources\nCheck out Austin's Universal Recycling Ordinance & Timeline [Here] (http://austintexas.gov/uro)\nThe Universal Recycling Ordinance (URO) supports Austin\u2019s Zero Waste goal by requiring affected property owners to ensure that tenants and employees have access to convenient recycling. These properties include multi-family residential properties (e.g. apartments and condos), commercial non-residential properties and food enterprises:\nCheck out more awesome Open-Austin Projects Here\nInterested in a particular project? Come to the next Open-Austin Meetup\nHow to Contribute?\nView then Join the Hackpad!\nContributing\n\nGus Ireland\nPreston Pham\nDerek Gulledge\nMarco Pineda\n\nLicense\n  Released to the public domain under [the Unlicense](http://unlicense.org/) by Open Austin, 2015.\n\nContributing\n  Please see [CONTRIBUTING.md](CONTRIBUTING.md).\n\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nAustin Green Map\n\ud83c\udf33 See it live! open-austin.github.io/austingreenmap/ \ud83c\udf33\n\ud83c\udf4f Now on the App Store https://itunes.apple.com/us/app/green-map-interactive-map/id1022734155?mt=8 \ud83c\udf4f\nAn easy to browse gallery of the parks in Austin. Started at ATX Hack For Change 2015. Inspired by https://github.com/codeforboston/bostongreenmap.\nDevelopment in progress.\nInstall\ngit clone git@github.com:open-austin/austingreenmap.git\nnpm install -g gulp\nnpm install\n\nRun\ngulp clean && gulp\n\nDeploy\nTo deploy the webapp:\ngulp clean\ngulp build\ngulp deploy-gh-pages\n\nCordova\nTo run as a native iOS/Android app through Cordova see github.com/open-austin/austingreenmap-cordova.\nTo build the app for Cordova:\ngulp clean\ngulp build\ngulp inject-cordova\n\nData\nWe use PostGIS to transform the GeoJSON files, even though we should not. One day we'll fix this. To setup your PostGIS database follow the instructions at https://github.com/codeforboston/bostongreenmap.\npip install -r requirements.txt\nbrew install jq\nnpm install -g topojson\n./download.sh\n\nLicense\nReleased to the public domain under the Unlicense by Open Austin, 2015.\nContributing\nPlease see CONTRIBUTING.md.\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nMy take on the design of JKAN - a lightweight, backend-free open data portal, powered by Jekyll. Learn more about JKAN in the original .readme here.\nRead more about the project idea and history here\nAnd check out the existing design\nGet started\nTo start the site, run gem install bundler in the project directory. Once it is complete, run rake run and when started go to http://127.0.0.1:4000/data-portal/ in your browser.\nRebuilding assets for production builds\nIf you've edited any of the static assets, you may need to run npm run build\nto rebuild the asset bundle to get those changes to show up up on the\ngithub-pages hosted site. After building the bundle, commit the bundle file(s)\n(i.e. bundle.js) and push to github to make the changes live.\nCore Purpose of Site\nEnable folks to learn about, discover, and post links to open data.\nUser Testing:\nNotes on similar platform from Code for America Regional Data Portal Webinar\n\n\n\"It's tough to know where to start as a data user\"\n\nOverwhelm homepage with newb stuff\nTrim down categories for data explorer\nDistinct flows for posting & getting\n\n\n\n\"It's challenging to explain scientific data to non-scientists\"\n\nState purpose of collection\nExplain what the metadata means\nSuggest usage\n\n\n\n\"It's difficult to download an entire dataset and make it useful\"\n\nGive examples of use\nEncourage documentation & walkthroughs\nEncourage guest lectures at meetups\n\n\n\nSWOT\n\nStrengths\n\nStreamlined\nSimple\nLightweight\n\n\nWeaknesses\n\nUnwelcoming\nAssumes prior knowledge\nDoesn't demonstrate value\n\n\nOpportunities\n\nWelcome users\nDemonstrate value of open data\nHelp with projects\n\n\nThreats\n\nLicensing Issues w/ Datasets\nComplexity\nScope Creep\n\n\n\nDesign Challenge:\nMake the data portal newbie friendly without disrupting the flow of existing users.\nMake the design modular so that other cities can fork & replace our content.\nSitemap\nBefore\n\nAfter\n\nUser Stories\nAs a newbie, I can arrive at the homepage, read about what's going on, see some examples, and feel like I know how to get started.\nAs a visitor, I can go straight to the portal page to accomplish my task.\nAs a visitor, I can browse datasets by category and contributor.\nAs a visitor, I can view projects which correspond to a dataset.\nAs a visitor, I can figure out how to become a contributor.\nAs a visitor I can view a resource page to learn how to structure & store data, what tools to use to work with it, & how to get a project off the ground.\nAs a visitor, I can mark that I've used a dataset.\nAs a visitor, I can leave an evaluation for a dataset.\nAs a contributor, I can post a dataset.\nAs a contributor, I can link to a project I made using a dataset.\nInspiration\nStaying consistent with Open Austin branding makes a lot of sense.\nThe Opportunity Project provides examples of projects to demonstrate the value of open data.\nThe City of New York data portal is built on socrata but has designed around that. They must be doing something right since they are the #1 place in the US for open city data.\nSketches\nI decided to build out a homepage and resources page in addition to the portal.\nSmall\n\nMedium\n\nLarge\n\nWireframes\nSmall (Individual files here)\n\nMedium + (Individual files here)\n\nMockups\nSmall (Individual files here)\n\nMedium + (Individual files here)\n\n\n\n", "language": "HTML"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nPermit Prerequisite Check\n\n\nSet up and run locally\ngit clone git@github.com:open-austin/permit-prereq-check.git\ncd permit-prereq-check\nnpm install\nnpm start\n\nDeployment\ngit checkout master\nnpm run build\nnpm run deploy\n\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nTransportation Game Night\nGuess that Intersection\n\nOriginal Project Proposal\nGoogle Spreadsheet\n\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nvoteatx-svc2\nbackend redux\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.md\n      \n\n\ndata-portal-analytics\na place for scripts and datasets that study trends on the open data portal at http://data.austintexas.gov\nCurrent projects:\nA deep dive into usage metrics!\nData about how users interact with our open data portal is available in many places. This project is about gathering that data and sharing it with folks who want to study it. The goal --> inform how we manage the data portal!\n\n\n", "language": "Jupyter Notebook"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nInstabus 6.7\nThis is a rewrite of https://github.com/luqmaan/instabus.\nWhy rewrite Instabus?\n\nFetch data from the OneBusAway so that Instabus works for multiple cities (Austin, Tampa, Atlanta, etc.)\nAdd missing features like viewing the schedule for a stop or viewing nearby arrivals\nModernize the code, make it easier to read and easier to reason about\nBe available as mobile apps first through Phonegap and then through React-Native\n\nCheck out the issues labeled with components, to see what we're thinking for a new layout. https://github.com/open-austin/instabus/issues?q=is%3Aissue+is%3Aopen+label%3Acomponents\n\u26a0\ufe0f The code is still in the very early stages and is not ready for contributions. If you'd like to start contributing code, please let me know so I can have a sense of urgency and get the code ready.\nContributing\nWant to help? Have ideas for what the \"new\" Instabus should look like?\n\nOpen an Issue on this repo\nJoin the #instabus channel on the Open Austin slack: http://slack.open-austin.org\nTweet @luqmonster\n\nInstalling\nnpm install\nnpm start\n\nUse an editor with plugins for editorconfig and eslint.\nTests\nnpm run test\nnpm run test -- --watch --full-trace\n\nPrior Art\n\nhttps://github.com/luqmaan/instabus\nhttps://github.com/luqmaan/instabus-react\nhttps://github.com/luqmaan/MetroRappid-iOS\nhttps://github.com/sethgho/MetroRappidAndroid\n\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nVoteATX App\nThis app uses Google Maps, Bootstrap, and Knockout.js to display election information for citizens of Travis County (Austin), TX.  It is built off of the voteatx-svc backend.\nTo make it work for another County/City:\n\nProperly configure a new service (voteatx-svc) for that location\nUpdate the configuration constants at the top of the mappit.js file to point to the service\nUpdate the config constants to provide a new fallback lat/lon, as well as new bounds for autocomplete recommendations\nUpdate the about panel information in index.html to provide information relevant to the new voting locale\n\nContributors\n\nDesigned and implemented by Andrew Vickers\nGraphics by Gail Maynard\nOther contributors: Chip Rosenthal, Alvaro Montoro\n\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nsetup\nnpm install\nnpm start\n\nThe server will run on http://localhost:3000/\n\n/questions/:id\n/permits/:id\n\ntests\nnpm test\n\nInception\nThis project was pitched and started at ATX Hack for Change 2016\nThe contributors are as follows:\nProject Champion | Julia Robbins | Julia.robbins@austintexas.gov\nMichelle Armstrong | mimi314159@gmail.com\nVanessa MacDougal | vanessa.macdougal@gmail.com\nCody Gipson | cgipson06@yahoo.com\nVictoria O'Dell | victoria.d.odell@Gmail.com\nPreston Pham | prestonp08@gmail.com\nAthena Petropoulos | athenapetro@yahoo.com\nDaniel Lillja | daniel.lillja@gmail.com\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nCutePetsAustin @cutepetsaustin\nA twitter bot that posts a random adoptable pet from PetHarbor.com shelter(s).\nTo make it work with your city, simply change the shelters in credentials.py. You can find your shelter ID by inspecting a URL on PetHarbor.com, e.g. Austin = ASTN, and Denver = DNVR.\nForked from codeforamerica/CutePetsDenver.\nTweeting at @cutepetsaustin.\nQuickstart\n\nConfigure credentials.py\nInstall the dependencies pip install -r requirements.txt\nTweet a random adoptable pet python meow.py\n\nSetup\nRequirements\n\npython 2.7\npip - https://pip.pypa.io/en/latest/\nvirtualenv - http://virtualenv.readthedocs.org/en/latest/\n\nInstallation\n\nClone the repo git clone git@github.com:open-austin/CutePetsAustin.git\nConfigure credentials.py with your PetHarbor.com Shelter ID(s), Twitter API Key and Access Token:\n\nshelters = ['ASTN', 'DNVR']  # PetHarbor.com shelter IDs\ntwitter_api_key = 'XXXXX'\ntwitter_api_secret = 'XXXXX'\ntwitter_access_token = 'XXXXX'\ntwitter_access_token_secret = 'XXXXX'\n\nOptionally, create and activate a virtual environment\nInstall the python dependencies with pip install -r requirements.txt\nTweet a random adoptable pet with python meow.py\nOptionally, schedule a cron job to execute meow.py every few hours\n\nTwitter\n\nCreate a new Twitter app.\nOn the API key tab for the Twitter app, modify permissions so the app can Read and Write.\nCreate an access token. On the API Key tab in Twitter for the app, click Create my access token. Note: It's important to change permissions to Read/Write before generating the access token. The access token is keyed for the specific access level and will not be updated when changing permissions.\nCopy the API Key and Access Token into credentials.py\n\nLicense\nThe MIT License (MIT)\n\n\n", "language": "HTML"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nAustin Body Cam\nInformational site about Austin's body camera policy.\nDependencies\n\nJekyll\nRuby\n\nbundle install\njekyll serve # localhost:4000\n\n\n\n", "language": "HTML"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nguiding-principles\nDraft guiding principles for the city of Austin and our community\nWhat problem are we trying to solve?\nWe want to establish simple, memorable, and shareable principles to help guide our work, and provide an opportunity to include the culture of Austin in how we share them.\nWho will benefit (directly and indirectly) from this project?\n\ncitizens\ncity employees\ncurrent civic hackers\nnew civic hackers\n\nExamples of other guiding principles\n\nUK Government Digital Service\nCFPB Design Principles\nBBC GEL Design Philosophy\nCode for America Principles for a 21st Century Government\n\nContribution is needed!\nThis is open for contribution from anyone interested in helping form guiding prinples for the city and community. The issues in the repo are meant to be threads of discussion to help solidify language and princples around the purposed guidelines.\nMilestones\n\nAlpha- Get an iteration of the guidelines live and on a website\nBeta- Gather art for the guidelines posters from local artist and gov enthusiast.\nLaunch- Launch for the public. Final approvals\n\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nAustin Residential Permitting Application\n\n\n", "language": "Ruby"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nrecycling-bin \u267b\ufe0f\nThis is a fork of https://github.com/open-city/recycling.\nOur goals for this fork are to build:\n\nREST API that can be hosted easily on more than just Heroku. This means:\n\nNo Mongo dependency. Use a relational database like Postgres (or maybe GitHub pages).\nNo memcached dependency. We can figure out scaling later.\nhttps://github.com/open-austin/recycling-bin/issues/1\n\n\nFrontend that consumes the API. It should be just static files that can be hosted on GitHub pages.\n\nAPI\nThe API exposes two resources, locations and reports. A location can have many reports\nGetting all locations\ncurl -X GET localhost:8080/locations\n\nGetting a single location\ncurl -X GET localhost:8080/locations/{id}\n\nCreating a location\ncurl http://localhost:8000/locations -H 'Content-Type: application/json' -d '{\"name\": \"Capitol Factory\", \"coordinates\": [30.268748, -97.740364], \"address\": \"700 San Jacinto Blvd, Austin, TX 78701\"}'\n\nUpdating a location with a new report\ncurl -X PUT localhost:8080/locations/{id} -d {\"report\": \"Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium\"}\n\nLicense\nReleased to the public domain under the Unlicense by Open Austin, 2015.\nContributing\nPlease see CONTRIBUTING.md.\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nonebusaway-script\nThis is a collection of some scripts we're using to run OneBusAway in Austin. Feel free to copypasta whatever you'd like. Who knows if it works.\nTo use this script:\nChoose combined or separate webapps. \u26a0\ufe0f Combined currently does not work.\nInside will be either one or more data-sources.xml files (in xmlfiles folder for separate).\nYou must edit these to match your settings.\nseparate/xmlfiles/onebusaway-api-webapp/data-sources.xml\nseparate/xmlfiles/onebusaway-transit-data-federation-webapp/data-sources.xml\nseparate/xmlfiles/onebusaway-webapp/data-sources.xml\n\nOnce you have done this, you can optionally edit the script itself if you need to tweak it. All the variables are provided at the top for easier editing.\nFinally, don't forget to edit this block in the script:\n#Load Transit Bundle Data into SQL Database\necho \"Sending Bundle Data to Postgres Database... (This takes a while)\"\njava -classpath $DATABASELOADERFILE:$PSQLJDBCDRIVERFILE \\\n org.onebusaway.gtfs.GtfsDatabaseLoaderMain \\\n --driverClass=org.postgresql.Driver \\\n --url=jdbc:postgresql://localhost/oba \\\n --username=vincentliao \\\n --password=\"\" \\\n ./gtfs.zip\necho \"Complete!\"\n\nUsername and password will obviously be different, but you could also add it to a different database type using the respective JDBC driver.\nThen all you have to do is type:\ncd separate\nbash fresh_install_separate.sh\n\nor\ncd combined\nbash fresh_install_combined.sh\n\nto start the script!\nRequirements\nFor ubuntu 14, we needed to install:\nsudo apt-get install git\nsudo apt-get install openjdk-7-jdk\nsudo apt-get install maven\n\nYou'll also need to set up a database and point the data-sources.xml to it. We used Postgres on AWS RDS.\nUpdating the server\nDeploying GTFS url changes to the austin OneBusAway server\n# Deploying GTFS url changes to the austin OneBusAway server\n#\n# First make any config changes to /var/www/onebusaway-script/separate/xmlfiles/onebusaway-transit-data-federation-webapp/data-sources.xml\n# The relevant section is usually\n# <bean class=\"org.onebusaway.transit_data_federation.impl.realtime.gtfs_realtime.GtfsRealtimeSource\">\n#     <property name=\"tripUpdatesUrl\" value=\"http://localhost:6996/protobuf?url=https://data.texas.gov/download/rmk2-acnw/application/octet-stream\" />\n#     <property name=\"vehiclePositionsUrl\" value=\"http://localhost:6996/protobuf?url=https://data.texas.gov/download/eiei-9rpf/application/octet-stream\" />\n#     <property name=\"alertsUrl\" value=\"https://data.texas.gov/download/nusn-7fcn/application/octet-stream\" />\n#     <!-- Optionally set the refresh interval - how often we query the URLs, in seconds (default=30) -->\n#     <property name=\"refreshInterval\" value=\"5\"/>\n# </bean>\n\nBUILD_DIR='/var/www/onebusaway-script/separate/obatemp/'\nCONFIG_DIR='/var/www/onebusaway-script/separate/xmlfiles/'\n\ncp $CONFIG_DIR/onebusaway-transit-data-federation-webapp/data-sources.xml $BUILD_DIR/onebusaway-application-modules/onebusaway-transit-data-federation-webapp/src/main/resources/\ncd $BUILD_DIR/onebusaway-application-modules/onebusaway-transit-data-federation-webapp\nmvn package\n\nbash $BUILD_DIR/apache-tomcat-8.0.30/bin/shutdown.sh\ncp $BUILD_DIR/onebusaway-application-modules/onebusaway-transit-data-federation-webapp/target/onebusaway-transit-data-federation-webapp.war $BUILD_DIR/apache-tomcat-8.0.30/webapps\nbash $BUILD_DIR/apache-tomcat-8.0.30/bin/startup.sh\n\ntail -f $BUILD_DIR/apache-tomcat-8.0.30/logs/*\n\nLicense\nReleased to the public domain under the Unlicense.\nTo the extent possible under law, Vincent Liao and other Open Austin contributors have waived all copyright and related or neighboring rights to this work.\n\n\n", "language": "Shell"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nnode-gtfs-realtime\nExamples of using node.js to parse a GTFS-realtime feed.\nThis is experimental/prototype code, so don't count on it for anything. \ud83d\ude08\n\n\n", "language": "PureBasic"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nOPEN BY DEFAULT\nOpen Austin is drafting some priorities for Open Data & Open Government Policy at City Council.\nContribute by:\n\nReviewing the exisiting City of Austin Open Data Ordiance from 2011.\nAdding items or comments to our Policy Priorities Google Doc\nSuggesting a dataset for liberation\nJoining the #policy channel on our Slack chat\n\nPolicy Documents:\n\n2011 CoA Open Data Ordiance\n2013 CoA Open Government Directive\n2014 CoA Open Data Initiative 2.0 Directive\n\nOpen Data Plan Presentation to Dept Directors\n\n\nTexas Legislature Open Government Code\nTemplate for Community Tech & Telecom Recommendation\nOpen Austin Advocacy Agenda - 1 Jul 2015\n\nPolicy Guidelines, Reports, and Evaluations:\n\nSunlight Foundation: Open Data Policy Guidelines\nOmidyar Network: Six Stories About Open Data Impact in the UK\nOpen Data Progress Report\n\nArticles:\n\nWhy Portland Needs Open Data\n\nPolicy Team Meeting Notes:\n\nNovember 3, 2015\n\nSee the wiki for more\n\nStatements\nLocal Data is Open By Default - Public data sets must be considered open unless they contain information designated as sensitive, private, or confidential by federal or state law, rule or regulation or local law. It is the city\u2019s duty to ensure a system that embraces automation, ease and sustainability.\nActions\n1) Creation of CTTC Working Group - The City\u2019s Community Technology & Telecommunications Commission (CTTC) will form a working group to draft a formal recommendation for an open data ordinance for presentation to the Economic Opportunity Subcommittee of the City Council.\nRecommendations\n\n\nData is Machine Readable - This means releasing information in open formats (or \u201copen standards\u201d), in machine-readable formats, that are structured (or machine-processable) appropriately. Plainly, \u201copen formats\u201d refer to a rolling set of \u201copen standards,\u201d often defined by standards organizations, that store information in a way that can be accessed by proprietary or non-proprietary software means. These formats exist across an array of data types; a common example cited is CSV in lieu of XLS for spreadsheets (the former being accessible via a wider variety of software mechanisms than the latter). \u201cMachine-readability\u201d simply refers to a format that a computer can understand. For example, .PDF formats for documents are not an idea format for machine readability.\n\n\nData Catalog - For an open data policy to have a strong foundation, you first need to know what data you have\u2014and so does the public. Governments should conduct an inventory of existing data early in the process of open data policy development in order for the government and other stakeholders to be aware of the full potential dimensions of data release. While defining total information holdings may be a complex undertaking, governments should conduct as comprehensive a review of existing data information as possible, with the inclusion of information holdings that may benefit from becoming structured data themselves.\n\n\nPrioritize and Release - The The new working group will prioritize based on the catalog for the next year\u2019s goals. As part of the first year\u2019s guarantees, we recommend that one high value data set, based on community input, to be released under the new accessible guidelines.\n\n\nLicensed Free - The City of Austin shall license any data it publishes for free re-use to ensure clarity of copyright without legal responsibility or liability for publishing such data.\n\n\nContracted products and services must adhere - To ensure that the public retains access to its data, provisions should added whenever possible to the existing procurement, contracting or planning processes requiring government contractors release government relevant information openly.\n\n\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nPull Data Portal Catalog\nPull all the metatdata on datasets published at data.austintexas.gov\nand dump a JSON structure to stdout.\nElements are:\n\ncount: number of data catalogs\nsearchType: \"views\"\nhost: data portal hostname\ntimestamp: time at which pull occurred, integer seconds since epoch\nresults: array of catalog metadata, one entry per dataset\n\nThe accompanying \"run-pull-catalog.sh\" is designed to be run\nnightly from cron, to capture a dump to data.open-austin.org.\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.md\n      \n\n\ncapture\nA repo to answer questions about public transit in Austin. CapMetro vehicle location data is collected by [scascketta/CapMetrics](https://github.com/scascketta/CapMetrics].\nTo start, this project will try to answer:\n\nIs the 801 faster than the 1? If so, where?\n\nhttps://github.com/open-austin/project-ideas/issues/3\nInstallation\n\nClone the capture repository https://github.com/open-austin/capture\nClone the CapMetrics repository https://github.com/scascketta/CapMetrics\nInstall the requirements via pip install -r requirements.txt\nRun one of the examples in the Usage section.\n\nUsage\n$CAPMETRICS_PATH is the path to the CapMetrics repository.\ndistance.py transforms a day of vehicle locations into trips with travel time, given a route id and the coordinates for two stops along the route.\nTo get the travel times for the 801 between Triangle Station and Republic Square Park Station on June 3, 2015:\npython distance.py --route_id 801 --name triangle-to-republic --begin_lat 30.162883 --begin_lon -97.790317 --end_lat 30.266218 --end_lon -97.746056  --glob \"2015-06-03\" --capmetrics_path ../CapMetrics\nTo get the travel times for the 801 between Tech Ridge Bay I and Southpark Meadows Station for all days in 2016:\npython distance.py --route_id 801 --name techridge-to-southpark --begin_lat 30.418199 --begin_lon -97.668243 --end_lat 30.162883 --end_lon -97.790317  --glob \"2016*\" --capmetrics_path ../CapMetrics\nTo get the travel times for the 1 between Tech Ridge Bay D and Bluff Springs/William Cannon for all days in 2016:\npython distance.py --route_id 1 --name techridge-to-cannon --begin_lat 30.418534 --begin_lon -97.668904 --end_lat 30.189427 --end_lon -97.767879  --glob \"2016*\" --capmetrics_path ../CapMetrics\nData for the visualizations:\n801 vs 1\n# end to end\npython distance.py --route_id 1 --name techridge-to-cannon --begin_lat 30.418534 --begin_lon -97.668904 --end_lat 30.189427 --end_lon -97.767879  --glob \"2016*\" --capmetrics_path ../CapMetrics\npython distance.py --route_id 801 --name techridge-to-southpark --begin_lat 30.418199 --begin_lon -97.668243 --end_lat 30.162883 --end_lon -97.790317  --glob \"2016*\" --capmetrics_path ../CapMetrics\n# triangle to republic square\npython distance.py --route_id 801 --begin_lat 30.162883 --begin_lon -97.790317 --end_lat 30.266218 --end_lon -97.746056 --name triangle-to-republic --glob \"2016*\" --capmetrics_path ../CapMetrics\npython distance.py --route_id 1 --begin_lat 30.162883 --begin_lon -97.790317 --end_lat 30.266218 --end_lon -97.746056 --name triangle-to-republic --glob \"2016*\" --capmetrics_path ../CapMetrics\n803 vs 3\n# end to end\n\n# northloop to republic square\npython distance.py --route_id 803 --begin_lat 30.326284 --begin_lon -97.739566 --end_lat 30.266218 --end_lon -97.746056 --name triangle-to-republic --glob \"2016*\" --capmetrics_path ../CapMetrics\npython distance.py --route_id 3 --begin_lat 30.326284 --begin_lon -97.739566 --end_lat 30.266218 --end_lon -97.746056 --name triangle-to-republic --glob \"2016*\" --capmetrics_path ../CapMetrics\nInstallation\n\ngit clone git@github.com:scascketta/CapMetrics.git\ngit clone git@github.com:open-austin/capture.git\ncd capture\npip install -r requirements.txt\n\n\n\n", "language": "Jupyter Notebook"}, {"readme": "\n\n\n\n        README.md\n      \n\n\ncivic-tech-canvas\nA version of the business model canvas that we hacked for civic tech project planning\nTo click links and download the canvas files, go here: http://cityofaustin.github.io/civic-tech-canvas\n\n\n", "language": "HTML"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nHack_Summit_Project_Plans\nThis document needs to be written.\nAll 11 project plans have been entered into this repo.\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\n\nCodeAcross 2016\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nmeetup-proxy-aws-lambda\nA proxy for the Meetup.com API that lives in AWS Lambda & API Gateway. We're using this to embed the upcoming Open Austin events on our website.\nGive our Meetup.com proxy a whirl: https://lhtgmc37pi.execute-api.us-west-2.amazonaws.com/prod/meetup-proxy-aws-lambda.\nThe reason this project exists is because:\n\nThe Meetup.com widgets are ugly and only show one event.\nThe Meetup.com API doesn't have a public endpoint to get events for a Meetup.\nI don't want to expose my Meetup.com API key publicly.\n\nSince my key is in the lambda, you might be able to do something evil with it. But because all this code does is call /events?group_urlname=Open-Austin, this should limit the damage. Hopefully.\nContributing\nFirst installing some things:\nnpm install\n\nAdd a src/secrets.json file that looks like this:\n{\n    \"meetup_api_key\": \"....................\"\n}\nYou can get a Meetup.com API key from https://secure.meetup.com/meetup_api/key/.\nThen confirm it works:\nnpm run test\n\nDeploying\nTo update the lambda function first install the AWS-CLI, get AWS credentials from @luqmaan, and then run this:\n./lambda.sh\n\nSetting up the Lambda & API Gateway project for the first time\nIf you'd like to copy this lambda to your own AWS account, here's how I did it.\n\nGo to AWS Lambda and create a Lambda\nUse the microservice-http-endpoint blueprint.\nUse the zip file created by running the ./lambda.sh command.\nFinish setting up the API Gateway using the defaults.\nChange the API Gateway settings to not require authentication on the endpoint. I had it sent to IAM and things were sad.\nEnable CORS to allow requests from any domain.\n\nQuestions\nHave a question about this project? Open an issue or contact us on the Open Austin Slack chat. slack.open-austin.org\nLicense\nThe code for this repository has been released into the public domain by Open Austin via the Unlicense.\nCreated by @luqmaan.\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nonebusaway-docker\n\u26a0\ufe0f Look at https://github.com/open-austin/onebusaway-script/, its works more! \u26a0\ufe0f\nDocker scripts to start a OneBusAway server.\nWe're creating this as part of https://github.com/open-austin/project-ideas/issues/21.\nRunning the OBA Docker\ndocker build -t oba .\ndocker run -p 8080:8080 -t oba\nDOCKER_IP=$(docker-machine ip default)\ncurl http://$DOCKER_IP:8080/api/where/agencies-with-coverage.json?key=web\n\nCity specific data:\n\ngtfs.zip\nDockerfile\n\ngtfsRealtimeAlertsUrl\ngtfsRealtimeTripUpdatesUrl\ngtfsRealtimeVehiclePositionsUrl\n\n\n\nDeploying to Azure\nhttps://github.com/Azure/azure-quickstart-templates/tree/9ad72f1f5f0008c14311be79eee036b871712394/docker-simple-on-ubuntu\npbpaste > {\"username\":\"NewUsername\", \"password\":\"NewPassword\", \"ssh_key\":\"\", \"reset_ssh\":false, \"remove_user\":\"\"}\nazure vm extension set Default MyDockerVM VMAccessForLinux Microsoft.OSTCExtensions \"1.2\" --private-config-path  PrivateConf.json\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nLeaflet lightning talk\n\u26a1\ufe0f powered by https://github.com/hakimel/reveal.js \u26a1\ufe0f\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nopen-austin-logo\nThis project contains the Open Austin logo assets.\n\nLogo_OpenAustin - Logo assets saved as .ai, .eps, .pdf, .png, .jpg, & .svg.\nSwag_OpenAustin - Logo assets for buttons, t-shirts, and stickers.\nPast_Logos - previous versions of our logo.\n\nOur current logo was designed by Victoria O'Dell (@victoriaodell).\nPrevious versions of our logo were designed by Travis Hohl (@travishohl) & Leah Roberts.\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nAustin's Open Data Initiative\nThis repo is used to develop and publish documents about the City of Austin's Open Data Initiative. The docs, like the Initiative, are always changing, and this repo helps collaborators improve the docs while preserving older versions for reference.\nWe need contributors and reviewers!\nHow to contribute\nDetails forthcoming...\nin the meantime, edit a markdown file or leave an issue\n\n\n", "language": "HTML"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nAustin Parks Equity App\nThis is a civic app that aims to help visualize how Austin's park resources are distributed throughout the City of Austin.\n###Status: under development\n###Related News:\n\nDoes Austin spend enough on parks? - Nov 19, 2015 \nDistrict 4 residents want more parks, connectivity - June 3, 2015\nCouncil Member Houston sees disparity in treatment of parks - May 20, 2015\nDistrict 4 community meeting on parks - April 30, 2015\nNorth Austin green space becomes a priority for council - March 25, 2015\n\nSee our progress: Live Demo\nRunning Code Locally:\n1. npm is required\nnpm is Node's package manager. You can install Node at their site or with a command like brew install node if you use Homebrew.\n2. gulp is required\ngulp is used to build and run the app. Before you can serve the app locally, you need to install gulp cli:\n$ npm install -g gulp\n\n3. webpack is required\nwebpack is used to bundle assets\n$ npm install -g webpack\n\nTo bundle assets:\n$ webpack\n\n4. install npm dependencies\nInstall the npm dependencies:\n$ npm install\n\n5. run the development server\nTo run the local server and see the app in your browser:\n$ npm start\n\nServes the app at http://localhost:8080.\nTo (re)build data files:\nThe data processing workflow is (for the most part) automated with a Makefile\nin the data/ directory. This workflow assumes a UNIX operating system (such as\nOS X or Linux). You'll also need:\n\nnode / npm\nruby\nogr/gdal\n\nTo build data files, cd into the data/ directory:\n$ cd data\n\nAnd run make\n$ make\n\nIf you want to rebuild or update a file, just delete it and re-run make. At the\nmoment, not everything has been ported over to the Makefile, so this won't\nwork for all files.\nData sources & use:\n\nCity of Austin, Parks and Rec Dept (PARD) Data\n\nBasic Park Feature Layer via ArcGIS Server\n\nAlso available on data.austintexas.gov\nThis data is used across the app to produce park shapes.\n\n\nPark Amenity Points\n\nThis data is used to calculate whether a park is \"undeveloped\" or \"developed\".\n\n\nPark Facility Points\n\nThis data is used to calculate whether a park is \"undeveloped\" or \"developed\".\n\n\nPark Trails\n\n\nOpen Street Map Park Data:\n\nWe use the Overpass API via the \"query-overpass\" plugin to extract data. Here's the commit that added OSM data if you're curious how.\nWe use this data to expose privately owned but publicly accessible parks that PARD doesn't maintain.\n\n\nCensus.gov Data\n\nDistrict Demographic Data via City of Austin Demographer.\nCitySDK API\n\nWe use this data to show park need and compare districts.\n\n\n\n\n\nArchitectural Decisions & Known Issues:\n\nOur javascript files are messy. Based on the way this project grew from one map to many, we are currently making a separate js file for each html page. This is bad and should eventually be fixed.\nFor the park access heatmap, we ran a GIS process in ArcGIS. This static heatmap layer isn't response to park layers being toggled on and off. We'll probably use CartoDB to host these heatmaps in the future and rely on their PostGIS servers to create simplified buffers vs the cost-distance analysis heatmap we are currently working with.\nQuestion about why or how we did something? Create an issue!\n\n##Credits\n\nMaintainer: @mateoclarke - dev\n@kyoder - GIS Data Analysis\n@wilsaj - GIS & dev\n@fremn - dev\n@luqmaan - dev\n@mattybow - dev\n@johntryee - dev\n\nUnlicense:\nReleased to the public domain under the Unlicense by Open Austin, 2015.\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nShip It Weekend 2015\nList of projects:\n\n\n\nProject Title (link)\nRSVP\nNEEDS\nSOURCE\nTopics\n\n\n\n\nAustin Green Map\n\u2705\nUpdate Data, Reconsider Architecture, User Feedback\nGithub\nParks & Rec\n\n\nOpen By Default Policy Campaign\n\u2705\nReview Existing Policies, Suggest and comment on new priorities, Suggest Datasets for Liberation\nN/A\nPolicy & Open Data\n\n\nInstabus\n\u2705\nCreate a survey/some way of getting user feedback. Python skills: Update GTFS data. Javascript skills: Improve page titles. Show nearby routes.\nGithub\nPublic Transit\n\n\nTransitime\n\u2705\nJava + Docker skills required: Transitime generates transit predictions. Our Transitime instance needs to be updated to the latest version and needs some configuration changes to improve predictions.\nGithub\nPublic Transit\n\n\nRecyling Bin (aka My Building Doesn't Recycle)\n\u2705\nFront end app that consumes the backend API needs work. Site Design, javascript mapping and other features, User Testing, More Research, Marketing\nBackend Repo & Frontend Repo\nRecycling & Sustainability\n\n\nDigitalATX.org\n\u2705\n[UX/UI design needed for Lab Profile pages, Add Editing capabilities to  Lab Profile pages, Add search functionality on Location Inventory page for zipcode & organization, Build blogging interface for \"Storytelling\" page, Add user/credential functionality, User testing, particularly on mobile and different browsers] (https://github.com/DigitalInclusion/digitalatx/issues/9)\nGithub\nDigital Inclusion & Community Organizing\n\n\nData Portal Analysis\n\u2705\nTODO\nGithub\nOpen Data\n\n\nOpen Data Progress Report\n\u2705\nMobile UX () link to new data liberated\nGithub\nOpen Data\n\n\nBill Tracker\n\u2705\nTODO\nGithub\nState Government\n\n\nAustin Park Equity\n\u2705\nJavascript, Incorporate more census data, consolidate data source from OSM\nGithub\nParks Access\n\n\nopen-austin.org\n\u2705\nTurn design comps into Jekyll code, migrate old content from WP\nGithub\nOA Admin\n\n\nOpenStreetMap ATX Buildings Import\n\u2705\nOpenStreetMappers to help import the building footprint and address point datasets from the City of Austin into OSM\nGithub\nOSM, GIS, Mapping\n\n\nTexas Appleseed\n\u2705\nBrowser Testing for Responsiveness. Alternative solution for large PDF downloads on mobile.\nGithub\nJustice & Education\n\n\nPet Alerts\n\nRails skills:  New features, fix timeouts, consider docker/vagrant. HTML/CSS Skills: Content fixes, CSS/styling issues\nGithub\nAnimal Services\n\n\nMyCreekATX\n\nTODO\nGithub\nEcology, Water, Environment, Community Organizing\n\n\n[City Council Agendas]\n\nScraping, Leaflet\nTODO\nOpen Data\n\n\n\nOther projects Open Austin has worked on this year:\n\nBudget In A Box App\n211 Data\nCapmetrics\nCity Paths User App & Policy Reports\nCivic Tech Project Planning Canvas\nCouncil Connect\nGranny Flats\nMap My Broadband\nNoise Complaints\nStreamlined City Portal UX\nZero Waste\nTransitime\nConstruction Permits\nPreterm Baby Warmer\nPedestrian Infrastructure Insights\nChange Is\nPublic Input for Infrastructure\nOccupy the Lege\nMonstralia\nCivic Engagement Management System\nLone Star Heritage Tourism Resource\nLesson Plan Wiki App\nStolen Bikes Database\nEcoNetwork Civic Education\nShow Us Your Austin\n\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nAustin Parks Photo Scraper\nThis project just provides photo urls for Austin Green Map.\nThe photos are sourced from Flickr with a\nCreative Commons license.\nThe data can be found in the /images directory which contains json data of\npark photos.\nSetup\nnpm install -g babel\nnpm install\ncp config.js.sample config.js\n\nNext, edit config.js with your information like api keys and other settings.\nRun scraper\nnpm start\n\nClean\nnpm run clean\n\nData access\nMake XHR requests to the github page in the format\nhttp://open-austin.github.io/austin-parks-photos/images/[Park ID].json\n\nHere's Zilker Park's data file: http://open-austin.github.io/austin-parks-photos/images/324.json\nNote: the gh-pages branch should only contain the images folder.\nLicense\nReleased to the public domain under the Unlicense by Open Austin, 2015.\nContributing\nPlease see CONTRIBUTING.md.\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nOpen Austin Demo Website\nThis package contains the demo websites that Open Austin has\nused at various events.\nTo access a given website you'll want to switch to that\nbranch.\n2015-atx-hack-for-change - For ATX Hack for Change, June 2015.\n2014-atx-gis-day - For ATX GIS Day, November\n2014. http://atxgisday.org/2014/\n2014-tx-govt-summit - For a table we provided at the Texas\nDigital Government Summit, June 2014. We particiated with\nCity of Austin and State of Texas in this event.\n2013-city-hall-expo - For the ATX Civic Tech Expo that we\nconducted at Austin City Hall, May 2013.\nWorkflow\nCreate a new website\nEach version of the website is a branch. To create a website for a new event, start with a website of an existing event and fork it to a new branch. For example, let's create 2016-example-site from 2015-atx-hack-for-change.\ngit checkout 2015-atx-hack-for-change\ngit checkout -b 2016-example-site\ngit push --set-upstream origin 2016-example-site\n\nUpdating a website\nWhen you want to update a website, be sure to checkout the proper branch. This example shows the process to update the 2016-example-site website.\ngit checkout 2016-example-site\n(make changes)\ngit commit -a\ngit push\n\nPublishing website updates\nTo publish a branch, say 2016-example-site, to the github.io site, use this process.\ngit checkout gh-pages\ngit merge 2016-example-site\ngit push\n\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\ntecfiler\nUtility to generate campaign finance filings for candidates/office-holders and specific\npurpose committees.\nThis project is in development.\nFor design information, please see the wiki: https://github.com/chip-rosenthal/tecfiler/wiki\nBackground\nThe requirements for candidate and lobbyist disclosures are set by the Texas\nEthics Commission (TEC): http://www.ethics.state.tx.us/main/local.html\nLocal candidate and lobbyist disclosures are filed not with the State, but with\nthe Austin City Clerk.\nClerk takes filings on paper (or PDF versions of the forms).\nThe filings are posted online but are not easily searchable:\nhttp://www.austintexas.gov/department/campaign-finance-reports\nIn April, the City Council passed an ordinance to create an online, searchable\ndatabase of campaign and lobbyist filings:\nhttp://www.austintexas.gov/edims/document.cfm?id=169484\nInitial staff estimates to implement have come back with: about 800K cost,\nabout a year development, solution based on proprietary technology\nIn a meeting organized by Councilmember Morrison, city staff was open to the\nidea of a \"civic sourced\" effort to help reduce costs and time.\nSome complexities not addressed:\n\n\nThere are additional forms, such as the treasurer filing and correction\nfilings, that are not scoped at this time.\n\n\nThere are additional schedules that the City of Austin uses, that are not\nscoped in this discussion.\n\n\nLocal government can require electronic filings, but the process is going to\nneed TEC approval.\n\n\nTEC Forms\nForm C/OH: Candidate/Office-Holder Campaign Finance Report\nhttp://www.ethics.state.tx.us/forms/coh.pdf\n\nSchedule A: Political Contributions other than Pledges or Loans\nSchedule B: Pledged Contributions\nSchedule E: Loans\nSchedule F: Political Expenditures\nSchedule G: Political Expenditures Made from Personal Funds\nSchedule H: Payment from Political Contributions to a Business of C/OH\nSchedule I: Non-Political Expenditures made from Political Contributions\nSchedule K: Interest Earned, Other Credits/Gains/Refunds, and Purchase of Investments\nSchedule T: In-Kind Contribution or Political Expenditure for Travel Outside of Texas\n\nForm SPAC: Specific-Purpose Committee Campaign Finance Report\nhttp://www.ethics.state.tx.us/forms/spac.pdf\n\nSchedule A: Political Contributions other than Pledges or Loans\nSchedule B: Pledged Contributions\nSchedule C: Corporate or Labor Organization Contributions other than Pledges or Loans\nSchedule D: Pledged Corporate or Labor Contributions\nSchedule E: Loans\nSchedule F: Political Expenditures\nSchedule H: Payment from Political Contributions to a Busines of C/OH\nSchedule I: Non-Political Expenditures made from Political Contributions\nSchedule J: Political Contributions Returned to Committee\nSchedule K: Interest Earned, Other Credits/Gains/Refunds, and Purchase of Investments\nSchedule T: In-Kind Contribution or Political Expenditure for Travel Outside of Texas\n\nTEC Automation and Import Format\nThe state provides free software for electronic filing with the state. The software can\nbe used to generate reports for local filing, but does not support electronic filing locally.\nThe state software allows import of contributions and expenditures. Our tool will be\nmodeled around this import format. It is documented in the TX-CFA Import Guide:\nhttp://www.ethics.state.tx.us/whatsnew/ImportGuide.pdf\nDevelopment Status\nThere is currently a prototype \"import engine\" that would load CSV files in a standard form\ndefined by the TEC, save them in a database, and (if desired) produce the standard TEC forms as PDFs.\nNow that we've got a workable data model and PDF rendering tool, we'd like to build a web-based app.\nWhen complete, this will provide a complete solution for campaigns to file their financial reports,\nand provide public transparency to funds in the political system.\nThe import engine is written in ruby, and the web framework has been created in rails.\nThey need to be merged.\nInstallation Notes\nThese instructions will help get the rails web framework installed. The import engine\ncurrently lives in the dm-import-engine branch.\ngit clone https://github.com/chip-rosenthal/tecfiler.git\ncd tecfiler\nbundle install\n\n\n\nCopy config/database_example.yml to database.yml and edit it for your preferred db.\n\n\nCopy config/email_example.yml to email.yml and edit it for your email server settings. Devise is configured to require account confirmation via email.\n\n\nMigrate the database:\nbundle exec rake db:migrate\n\n\nStart the web server:\nrails server\n\n\nGo to http://localhost:3000/\n\n\nAdmin interface is at http://localhost:3000/admin (demo account login is \"admin@example.com\" and password is \"password\")\n\n\nUnit Tests\nYou can run the unit tests by running:\nbundle exec rspec spec/models\n\nAt this time, only \"models\" tests are implemented. You may encounter failures\nif you try to run the entire \"spec\" suite.\nYou can perform all tests in a single spec file with a command such as:\nbundle exec rspec spec/models/contribution_spec.rb\n\nor a single test case by including a line number, such as:\nbundle exec rspec spec/models/contribution_spec.rb:14\n\nAn in-memory database is used for test mode (RAILS_ENV=\"test\"). This speeds\nup testing a bit. (But not enough, it still takes a painful amount of time\nto bring up the Rails stack for testing.)\nProduction Notes\nBefore running in a production environment, be sure to update the secret token to a unique value:\nrake secret\n\nEdit your config/initializers/secret_token.rb file to add the secret token:\nTecfilerAr::Application.config.secret_token = '...some really long, random string...'\n\n\n\n", "language": "Ruby"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nLiberate the Data\nCollecting datasets the community would like to see published in a machine readable format.\n\ud83c\udf1e Datasets we would like to see liberated \ud83c\udf1e\n\ud83c\udf1f Request a dataset \ud83c\udf1f\nTemplate for New Dataset Ideas\n(Copy and paste the below into a new issue.)\n**Concise description**:\n\n**Government agency/ies to contact**\n\n**Link (more details/brain dump/alpha)**\n\n**Who will use/benefit from this data?**\n\n**Specific Ideas for use of the data**\n\nHow To Propose or Discuss Liberating Datasets\nGitHub Issues work just like any other commenting system on the Internet. First, you'll need to create an account. Then you have two options: (1) comment on an existing idea (a.k.a. \"issue\"), or (2) create a new idea.\nIf you see an idea that you're interested in, click on it, read the discussion, and then add your thoughts to the bottom of the discussion thread. If you don't see the idea you have in mind, add a new one. You'll need a title and description and we encourage you to use the Template above. Then, someone from the Open Austin Core Team will respond, likely with some questions or feedback.\nGoals for this project\nWe are still thinking about how this turns into action. Here are some ideas:\n\nShow the City and other government agencies specific community interest in datasets or questions of licensing and use.\nBegin to think of programmatic ways to request this data as individuals and as Open Austin.\nLong term, pie-in-the-sky dream is a regional open data portal maintained \"by the people, for the people.\" This would be a place were you could dump Public Information Request data. It would be a more user friendly version of http://data.open-austin.org/\n\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nCitySDK Austin Parks\nThis is a demonstration app forked from Austin Park Equity to give a mapping example using the CitySDK from Census.gov. We'd love for you to try to plug in data from your city.\nSee what the live Austin demo lookes like.\nWhat is the CitySDK?\nCitySDK is a toolbox for civic innovators to connect local and national public data developed by the US Census Department. You should explore their wonderful guides and documentation.\n\nCitySDK\nCitySDK Guides\nCitySDK Code Examples\n\nRequests\nHere is an example of the request we are making for demographic data in Austin, Texas (Travis County):\nvar sdk = new CitySDK();\nvar censusModule = sdk.modules.census;\ncensusModule.enable(config.citySDK_token);\n\nvar request = {\n  \"lat\": config.city_lat,\n  \"lng\": config.city_lng,\n  \"level\": \"county\",\n  \"sublevel\": \"true\",\n  \"api\" : \"acs5\",\n  \"variables\": [\n    \"population\",  // Total Population\n    \"income\",  // Median Income\n    \"poverty_family\",  // Number of Families Below Poverty\n    \"poverty\",  // Number of x Below Poverty\n    \"B01001_003E\",  // Male:!!Under 5 years\n    \"B01001_004E\",  // Male:!!5 to 9 years\n    \"B01001_005E\",  // Male:!!10 to 14 years\n    \"B01001_006E\",  // Male:!!15 to 17 years\n    \"B01001_027E\",  // Female:!!Under 5 years\n    \"B01001_028E\",  // Female:!!5 to 9 years\n    \"B01001_029E\",  // Female:!!10 to 14 years\n    \"B01001_030E\",  // Female:!!15 to 17 years\n    \"C27012_001E\",  // Total Health Insurance Coverage Status and Type by Work Experience by Age\n  ]\n};\n\ncensusModule.GEORequest(request, function callback(response) {\n   // Do stuff\n});\nThis cURL command would make the same type of request:\n$ curl 'http://api.census.gov/data/2013/acs5?get=NAME,B01003_001E,B19013_001E,B17012_002E,B17001_002E,B01001_003E,B01001_004E,B01001_005E,B01001_006E,B01001_027E,B01001_028E,B01001_029E,B01001_030E,C27012_001E&for=tract:*&in=county:453+state:48&key=YOUR_TOKEN'\n\nGET http://api.census.gov/data/2013/acs5\n    get=NAME,B01003_001E,B19013_001E,B17012_002E,B17001_002E,B01001_003E,B01001_004E,B01001_005E,B01001_006E,B01001_027E,B01001_028E,B01001_029E,B01001_030E,C27012_001E\n    for=tract:*\n    in=county:453+state:48\n    key=YOUR_TOKEN\nForking this repo\n1. Getting Started\nFind park data: The first thing you should do is look for park data from your city. Many cities and counties have a data portal. In Austin, we found raw park GIS data through the City's Socrata Open Data Portal.\nOften times, this data will be in a format best for analysis with desktop GIS software. For this web map, the ideal data type is geojson. But if it is in Shapefile format, that is ok too. But we'll worry about converting the file type later. Check out this blog post to learn why .geojson is nice and to learn how to convert data into geojson.\nFork the repo: Did you find a .geojson, .json, .shp (Shapefile), or .kml file with park polygons? Awesome. We'll make sure to convert that data into the best format in a later step. Now, you should go ahead and fork this repo to your own Github account. Once you've forked the repo and cloned it down from your own Github repo to your local machine, go ahead and follow the steps below...\nIf you couldn't find some park data, but you still want to play along. Try using this data from Oakland.\n2. Running Code Locally\n1. npm is required\nnpm is Node's package manager. You can install Node at their site or with a command like brew install node if you use Homebrew.\n2. webpack is required\nwebpack is used to bundle assets\n$ npm install -g webpack\n\n3. install npm dependencies\nInstall the npm dependencies:\n$ npm install\n\n4. run the build system && development server\nTo bundle assets, run the local server and see the app in your browser:\n$ npm start\n\nNPM will serve the app at http://localhost:8080.\n3. Import you own park data\nBack in Step 1, we wanted to make sure you could find park data from your city. Now's the time to import it into the app. We save our GIS file into a directory called /data. See that directory here on Github. Now that your raw data is imported, its time to convert your data to .geojson (if its not already). I suggest you follow the instructions in this blog if you haven't used ogr2ogr or coverted Shapefiles to geojson before. Last step here, rename your file to parks.geojson. This is what the code is expecting that park layer to be called. You'll need to either delete or rename the Austin park layer that came down with the repo.\n4. Config and customize the app to your city\nUpdate the config file. Go into the config file and update things like the coordinates of your city and your own CitySDK token (which you should request here).\nBuild new features. Add new features. The main javascript code live in the js/app.js file\nAustin Data Sources\n\nCity of Austin, Parks and Recreation Department (PARD) Data\n\nBasic Park Feature Layer via ArcGIS Server\n\nAlso available on data.austintexas.gov\nThis data is used across the app to produce park shapes.\n\n\n\n\n\nGlobal Data Sources\n\nOpen Street Map Park Data:\n\nWe use the Overpass API via the \"query-overpass\" plugin to extract data. Here's the commit that added OSM data if you're curious how.\n\n\nCensus.gov Data\n\nCitySDK API\n\n\n\nUnlicense\nReleased to the public domain under the Unlicense by Open Austin, 2015.\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nMy Building Doesn't Recycle\nCrowdsourcing data about which residential buildings do not have recycling in Chicago\nThe app can currently be found at http://recycling.herokuapp.com\nRequirements\n\nNode.js\nMongoDB\nMemcached\n\nGetting Started\nFor more detailed instructions see the wiki\n\ninstall dependencies\nnpm install\nRun mongod and memcached on default ports\nrun the app\nnode server.js\nThen visit http://localhost:3000 in your browser.\n\nTests\nRun the tests with npm test\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.rdoc\n      \n\n\n\nVoteATX Service\nVoteATX is a voting place finder application for Travis County elections.\nIt is provided in two projects:\n\nvoteatx-app \u2013 The front-end application. github.com/open-austin/voteatx-app\n\nvoteatx-svc \u2013 The back-end web service (this project). github.com/open-austin/voteatx-svc\n\nThis program has been tested with Ruby vesions 1.9.3 and 2.0. It requires\nSqlite3 database with Spatialite extensions.\nImportant: For more information on setting up Spatialite on your\nsystem, see: github.com/chip-rosenthal/findit-support#spatialite-support\nOnce the package is downloaded (and Spatialite has been installed), run:\n$ bundle install\nFor development, you can run the application from the command line:\n$ bin/voteatx-svc \nStarting VoteATX::Service ...\nCONFIGURE: environment = development\nCONFIGURE: root = /home/chip/Workspace/voteatx\nCONFIGURE: public_folder = /home/chip/Workspace/voteatx/public\nCONFIGURE: database = /home/chip/Workspace/voteatx/voteatx.db\n[2013-10-19 16:24:20] INFO  WEBrick 1.3.1\n[2013-10-19 16:24:20] INFO  ruby 1.9.3 (2012-04-20) [x86_64-linux]\n== Sinatra/1.4.3 has taken the stage on 4567 for development with backup from WEBrick\n[2013-10-19 16:24:20] INFO  WEBrick::HTTPServer#start: pid=4838 port=4567\nIf you get an error such as:\nSQLite3::SQLException: libspatialite.so: cannot open shared object file: No such file or directory (Sequel::DatabaseError)\nthat means your Spatialite library could not be located. You will need to\nspecify the Spatialite library location when you start up the service. Use\na command such as:\n$ SPATIALITE=/usr/lib64/libspatialite.so.5.1.0 bin/voteatx-svc\nThen, browse localhost:4567 to see the\nrunning application.\nThe application has been deployed using Phusion Passenger (mod_rails) under\nApache.  The \u201cconfig.ru\u201d file is used in production.\nDocumentation\n\nREADME-API.md describes the web services API\n\nREADME-data.rdoc provides information on setting up the database.\n\nAdditional documentation can be produced by running: rake rdoc\n\nFeedback\nPlease report any problems or feedback through the issue tracker for this\nproject: github.com/open-austrin/voteatx/issues\nThis program was written by Chip Rosenthal <chip@unicom.com>.\n\n\n", "language": "Ruby"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nHackathon Ideas\nThis repository contains community-curated civic project ideas for ATX Hack for Change 2014.\nThe ideas listed here have not yet been submitted as project proposals to the event. We need your help to refine these ideas, and then to identify a project champion who can submit it as a proposal. (The hackathon project proposals that have been submitted are here.)\nPlease respond by Fri, May 16, 2014 with your feedback.\nThe ideas are presented as individual files in this directory, which you can browse. If you browse these files online, github will display them nicely formatted.\nIf you want to participate in any of these projects, it is important that you register to attend the hackathon.\nCollected ideas:\n\nCivic FU\nGoogle Community Connections Dataset and Visualization Tool\nOpen311 vs. 10-One District Map\nPet Finder\nCreating How-To Content for Citizen Data Analysts\nCollect and Graph City Lobbyist Data\n[MetroRappid Android] (metrorappid_android.md)\n\nHow to contribute an idea.\nIf you have a github account, then:\n\nClone this repository.\nCopy the TEMPLATE.md file to a new file, called something like \"project_name.md\".\nChange the title at the top of the page to the project name.\nFill out the questionnaire.\n\nIf you do not have (and do not want) a github account then you could just download the template, fill it out with a text editor, and send it via email.\nStuff to know:\n\nThe file is formatted in Markdown style. Help here. Also, a nice, free and accessible markdown text editor to help you learn is called Mou (OSX only, sorry).\nHelpful information about hackathon project ideas here.\nThe careful observer may note that the template is based on the project submission form for the hackathon.\n\nHow to support an idea.\nIf you are potentially interested in working on this project, please express your support.\nYou will need a github account to support an idea.\nEach idea has a \"Github Issues\" thread created, where you can express your support. Find a link to the issue thread near the top of the idea page. Or, you can click the \"Issues\" icon to the right and see all the current issue threads.\nJust add your comment of support to the thread.\nHow to provide feedback for an idea.\nFeel free to use the \"Github Issue\" thread for an idea, discussed above. Or, if appropriate, create a new issue with your feedback.\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nAustin Recycles\nAbout\n\"Austin Recycles\" consists of a web application plus a web service that\nprovides trash and recycling pickup information for the City of Austin.\nMore info here: http://atxhack.wikispaces.com/Austin+Recycles\nDemo site: http://austin-recycles.open-austin.org/\nIssues and support queue: https://github.com/open-austin/austin-recycles/issues\nUsage\nFirst start the web service.  For development, run \"bin/austin-recycles\" from\na command line. For production, run via Phusion Passenger.\nThen, browse the \"index.html\" page.\nRequirements\nAt this time, the \"findit-support\" package must be manually installed\ninto the vendor directory. See: vendor/README\nThe SPATIALITE path may need to be specifically set when running the service:\nSPATIALITE=/usr/local/opt/libspatialite/lib/libspatialite.dylib bin/austin-recycles\n\nFor more information, see: vendor/findit-support/README.rdoc\nWeb Service API:\nThe web service provides a simple interface to retrieve service information\nfor a given location. The location is specified as degrees latitude and\nlongitude.\nHere is an example:\nREQUEST:\nGET http://localhost:4567/svc?latitude=30.362&longitude=-97.734 \n\nRESPONSE:\n{\n   \"origin\" : {\n      \"longitude\" : -97.734,\n      \"latitude\" : 30.362\n   }\n   \"routes\" : {\n      \"bulky\" : {\n         \"route\" : \"BU30\",\n         \"type\" : \"BULKY\",\n         \"next_service\" : {\n            \"period\" : \"WEEK\",\n            \"timestamp\" : 1376197200000,\n            \"status\" : \"PENDING\",\n            \"date\" : \"08/11/2013\",\n            \"day\" : \"Sun\",\n            \"slip\" : null\n         }\n      },\n      \"brush\" : {\n         \"route\" : \"BR22\",\n         \"type\" : \"BRUSH\",\n         \"next_service\" : {\n            \"period\" : \"WEEK\",\n            \"timestamp\" : 1368334800000,\n            \"status\" : \"PAST\",\n            \"date\" : \"05/12/2013\",\n            \"day\" : \"Sun\",\n            \"slip\" : null\n         }\n      },\n      \"recycle\" : {\n         \"route\" : \"RHAU14\",\n         \"type\" : \"RECYCLE\",\n         \"next_service\" : {\n            \"period\" : \"DAY\",\n            \"timestamp\" : 1371704400000,\n            \"status\" : \"PENDING\",\n            \"date\" : \"06/20/2013\",\n            \"day\" : \"Thu\",\n            \"slip\" : null\n         }\n      },\n      \"yard_trimming\" : {\n         \"route\" : \"HY10\",\n         \"type\" : \"YARD_TRIMMING\",\n         \"next_service\" : {\n            \"period\" : \"DAY\",\n            \"timestamp\" : 1371099600000,\n            \"status\" : \"PENDING\",\n            \"date\" : \"06/13/2013\",\n            \"day\" : \"Thu\",\n            \"slip\" : null\n         }\n      },\n      \"garbage\" : {\n         \"route\" : \"PAH60\",\n         \"type\" : \"GARBAGE\",\n         \"next_service\" : {\n            \"period\" : \"DAY\",\n            \"timestamp\" : 1371099600000,\n            \"status\" : \"PENDING\",\n            \"date\" : \"06/13/2013\",\n            \"day\" : \"Thu\",\n            \"slip\" : null\n         }\n      }\n   },\n}\n\nFor each route, the \"next_service\" fields indicate:\n\ntimestamp - The service date, milliseconds since epoch.\nperiod - Either DAY (the timestamp indicates the day on which service should occur)\nor WEEK (the timestamp indicates the start of the week in which service should occur)\ndate - Printable date, from the service date.\nday - Printable day of week, from the service date.\nstatus - ACTIVE (the service is happening now or about to happen), PENDING (the service\nis in the future), or PAST (the service has already occurred).\nslip - Number of days the service has slipped due to a holiday, or \"null\" if no slip.\n\nHelpful notes\nInstalling findit-support and spatialite\nCheck the \"vendor/README\" file for instructions for installing the findit-support package.\nQuery parameters for debug\nYou can add query parameters to the application to assist in debugging. Example:\nhttp://localhost/index.html?svc=http://austin-recycles.open-austin.org/svc&delay=5\n\nThe supported parameters are:\n\n\nsvc -- URL of the web service. By default, the web service URL is calculated\nfrom the document URL, i.e. the web service is assumed to be running on the\nsame server as the application. You may want to use this, for instance, if you\nare debugging the application locally, but want to use an instance of the web\nservice elsewhere.\n\n\ndelay -- A delay (in seconds) added for web service responses. The delay value\nis passed to the web service, which will delay by that amount before responding.\nI've used this, for instance, when I wanted to verify that the \"busy throbber\" is\ndisplaying correctly.\n\n\nt -- Value to use for current date. Must be a valid Date.parse() value, such as\n\"?t=July+3,+2014\".\n\n\nstatus -- Override calculated status of a service. The format is \"id:status[,id:status...]\".\nExample usage: http://stuff?status=recycle:active,bulky:past\nValid id values are: garbage, yard_trimming, recycle, brush, bulky.\nValid status values are: active, pending, past.\n\n\nDatabase browser\nIf you are working with the web service, you may want a tool to browse the database.\nThe SpatiaLite GUI app is a good tool. You also can use a SQLite tool, even though the\ngeometry columns will just appear as blobs. One option is:\nhttps://addons.mozilla.org/en-US/firefox/addon/sqlite-manager/\n\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nAbout\nThis is a partner to the Pet Alerts website, and acts as a simple data source, using the Austin, TX\nSocrata data portal from Austin Animal Center.\nInstall\ngit clone git@github.com:tshelburne/aac-pets-feed.git\nbundle install --path=vendor\nUsage\nCopy api-config.rb.EXAMPLE to api-config.rb\nThe distributed configuration is appropriate for posting to localhost:3000 -- i.e. a local development instance of the Pet Alerts app.\nFor production use, adjust settings of the api-config.rb file.\nRun with:\nruby scrape.rb\n\n\n", "language": "Ruby"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nCordova for Austin Green Map\nThis repo is used to compile https://github.com/open-austin/austingreenmap for Cordova/PhoneGap.\nInstallation\ngit clone git@github.com:open-austin/austingreenmap.git\ngit clone git@github.com:open-austin/austingreenmap-cordova.git\nnpm install -g cordova\ncd austingreenmap-cordova\n./init.sh\n\nUsage\nFirst, in the austingreenmap repo:\ngulp clean\ngulp build\ngulp inject-cordova\n\nThen in austingreenmap-cordova:\ncordova build ios\nopen platforms/ios/Green\\ Map.xcodeproj\nClick `Run`\n\n\n\n", "language": "Shell"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nAustin City Council Connect Project\nTrack city council agenda items with text and/or email message notification.\nAdd newly scraped agenda items\nTake it for a spin:  atxcc.tgregoneil.com\n\n\n", "language": "CSS"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nStolen Bikes\nhttps://austin.brightidea.com/ATXHack4Change2015/D200\n\nan ATX Hack for Change project\n\n\n", "language": "No language specified."}, {"readme": "\n\n\n\n        README.md\n      \n\n\nVanilla Rails Starter App\nThis is a Rails app with Bootstrap and Devise preinstalled for standardized responsive styling & basic user authentication.\n\n\n", "language": "Ruby"}, {"readme": "\n\n\n\n        README.md\n      \n\n\nOARK-back-end Bootstrap\nBootstrap apps for building a new backend-app\nEach of these is in of itself a back-end server bootstrap.  You can choose the language you are most familiar with and go from there.\nBelow are the frameworks used in each back-end.\nNode.js\nMVC\nSails.JS - Sails.JS Documentation\nTODO: Add Meteor and ExpressJS\nPHP\nTODO: FIll this in.\nRuby\nTODO: FIll this in.\n\n\n", "language": "JavaScript"}, {"readme": "\n\n\n\n        README.md\n      \n\n\n./\na Sails application\n\n\n", "language": "JavaScript"}, {"readme": "No readme file.", "language": "No language specified."}]